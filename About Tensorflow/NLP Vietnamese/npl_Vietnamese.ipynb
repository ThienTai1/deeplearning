{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"IYUvmCQMSo3j"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import nltk\n","\n","from sklearn.preprocessing import LabelEncoder\n","\n","import tensorflow_hub as hub\n","import tensorflow as tf\n","from tensorflow import keras\n","import tensorflow.compat.v2.feature_column as fc\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13051,"status":"ok","timestamp":1695216372689,"user":{"displayName":"9370 _ Phạm Thiện Tài","userId":"17496006235026682420"},"user_tz":-420},"id":"e1uwdk_X0ulq","outputId":"ebfded9d-97e4-4a47-a8dc-60fd4916d4e1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.33.2-py3-none-any.whl (7.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n","Collecting huggingface-hub<1.0,>=0.15.1 (from transformers)\n","  Downloading huggingface_hub-0.17.2-py3-none-any.whl (294 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n","  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n","Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.17.2 safetensors-0.3.3 tokenizers-0.13.3 transformers-4.33.2\n"]}],"source":["pip install transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L-h3Mety0vWu"},"outputs":[],"source":["from transformers import TFBertModel\n","import transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BnsQp6Gqejja"},"outputs":[],"source":["df_train = pd.read_csv('/content/drive/MyDrive/Deep Learning/NLP Vietnamese/synthetic_train.csv')\n","df_val = pd.read_csv('/content/drive/MyDrive/Deep Learning/NLP Vietnamese/synthetic_val.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":562,"status":"ok","timestamp":1694965363487,"user":{"displayName":"9370 _ Phạm Thiện Tài","userId":"17496006235026682420"},"user_tz":-420},"id":"DSreov-N1wtO","outputId":"bdea74ff-3beb-4893-9f78-64b6dd96dd8a"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-1e3af37b-120d-464b-9066-8014e209f804\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence</th>\n","      <th>sentiment</th>\n","      <th>topic</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Đội ngũ bảo trì quá thưa thớt dẫn đến không đả...</td>\n","      <td>negative</td>\n","      <td>facility</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>The university's musical and artistic faciliti...</td>\n","      <td>neutral</td>\n","      <td>facility</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Phương pháp giảng dạy phù hợp với các đối tượn...</td>\n","      <td>neutral</td>\n","      <td>curriculum</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Chương trình học giúp tôi trở thành một chuyên...</td>\n","      <td>positive</td>\n","      <td>curriculum</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Tôi nghĩ rằng chương trình đào tạo có thể có t...</td>\n","      <td>neutral</td>\n","      <td>curriculum</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1e3af37b-120d-464b-9066-8014e209f804')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-1e3af37b-120d-464b-9066-8014e209f804 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-1e3af37b-120d-464b-9066-8014e209f804');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-dff8dbe2-33e6-469f-9e6e-09d12f589c2b\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dff8dbe2-33e6-469f-9e6e-09d12f589c2b')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-dff8dbe2-33e6-469f-9e6e-09d12f589c2b button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["                                            sentence sentiment       topic\n","0  Đội ngũ bảo trì quá thưa thớt dẫn đến không đả...  negative    facility\n","1  The university's musical and artistic faciliti...   neutral    facility\n","2  Phương pháp giảng dạy phù hợp với các đối tượn...   neutral  curriculum\n","3  Chương trình học giúp tôi trở thành một chuyên...  positive  curriculum\n","4  Tôi nghĩ rằng chương trình đào tạo có thể có t...   neutral  curriculum"]},"execution_count":57,"metadata":{},"output_type":"execute_result"}],"source":["df_train.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":493,"status":"ok","timestamp":1694962150214,"user":{"displayName":"9370 _ Phạm Thiện Tài","userId":"17496006235026682420"},"user_tz":-420},"id":"GDyxRuiZ4BXX","outputId":"f2b3c033-491a-4bdf-afbf-eeb99b471d62"},"outputs":[{"data":{"text/plain":["(8144, 3)"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["df_train.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1694962150215,"user":{"displayName":"9370 _ Phạm Thiện Tài","userId":"17496006235026682420"},"user_tz":-420},"id":"NMYTIXxIexHx","outputId":"5e0fb4cd-dc65-4eb9-873c-cd790a4838cb"},"outputs":[{"data":{"text/plain":["sentence     0\n","sentiment    0\n","topic        0\n","dtype: int64"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["df_train.isnull().sum()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1694962150215,"user":{"displayName":"9370 _ Phạm Thiện Tài","userId":"17496006235026682420"},"user_tz":-420},"id":"fnBbgtdkiWqi","outputId":"7b682d24-9797-4a1f-87b4-8d25834fa76d"},"outputs":[{"data":{"text/plain":["sentence     8144\n","sentiment       3\n","topic           4\n","dtype: int64"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["df_train.nunique()"]},{"cell_type":"markdown","source":["# Loại bỏ ký tự đặc biệt trong câu\n"],"metadata":{"id":"aFI4_HxkDJ7t"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"PSLSgn26nTPs"},"outputs":[],"source":["def preprocess_text(text):\n","    # Loại bỏ các ký tự không mong muốn\n","    text = text.replace(\",\", \"\")\n","    text = text.replace(\".\", \"\")\n","    text = text.replace(\"'\", \"\")\n","    text = text.replace(\"\\\"\", \"\")\n","    return text\n","\n","df_train[\"sentence\"] = df_train[\"sentence\"].apply(preprocess_text)\n","df_val[\"sentence\"] = df_val[\"sentence\"].apply(preprocess_text)"]},{"cell_type":"markdown","source":["# Gắn nhãn cho từng từ"],"metadata":{"id":"-jgOPNXMDaey"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1695044100270,"user":{"displayName":"9370 _ Phạm Thiện Tài","userId":"17496006235026682420"},"user_tz":-420},"id":"CQ6hBt213Jbd","outputId":"f08f1580-79df-4c6e-8165-bee051f41a6a"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'<OOV>': 1, 'và': 2, 'viên': 3, 'học': 4, 'sinh': 5, 'của': 6, 'rất': 7, 'không': 8, 'có': 9, 'giảng': 10, 'tôi': 11, 'các': 12, 'trường': 13, 'được': 14, 'tập': 15, 'trong': 16, 'người': 17, 'cho': 18, 'giúp': 19, 'này': 20, 'trình': 21, 'với': 22, 'việc': 23, 'một': 24, 'năng': 25, 'thầy': 26, 'để': 27, 'sự': 28, 'luôn': 29, 'là': 30, 'tạo': 31, 'ấy': 32, 'dạy': 33, 'cô': 34, 'những': 35, 'bạn': 36, 'tốt': 37, 'giáo': 38, 'anh': 39, 'chương': 40, 'cảm': 41, 'nhiều': 42, 'thực': 43, 'phòng': 44, 'mình': 45, 'quá': 46, 'thể': 47, 'thấy': 48, 'đủ': 49, 'kiến': 50, 'cách': 51, 'khác': 52, 'bị': 53, 'ra': 54, 'động': 55, 'công': 56, 'tâm': 57, 'thức': 58, 'kỹ': 59, 'hiểu': 60, 'hơn': 61, 'thiết': 62, 'thường': 63, 'đầy': 64, 'khó': 65, 'the': 66, 'khi': 67, 'phát': 68, 'giải': 69, 'làm': 70, 'triển': 71, 'nghiệp': 72, 'đến': 73, 'môn': 74, 'hợp': 75, 'hoạt': 76, 'về': 77, 'quan': 78, 'thích': 79, 'bài': 80, 'chất': 81, 'tại': 82, 'tế': 83, 'đào': 84, 'dễ': 85, 'vực': 86, 'thiếu': 87, 'tình': 88, 'cơ': 89, 'thông': 90, 'chuyên': 91, 'cầu': 92, 'mới': 93, 'trợ': 94, 'khả': 95, 'đồng': 96, 'họ': 97, 'ta': 98, 'đưa': 99, 'tin': 100, 'ý': 101, 'cao': 102, 'hỗ': 103, 'cần': 104, 'lý': 105, 'đề': 106, 'nhóm': 107, 'sáng': 108, 'dụng': 109, 'đỡ': 110, 'thân': 111, 'khu': 112, 'tài': 113, 'thiện': 114, 'ứng': 115, 'tiện': 116, 'tính': 117, 'tiếp': 118, 'đáp': 119, 'nghiệm': 120, 'trang': 121, 'mọi': 122, 'gian': 123, 'lớp': 124, 'lượng': 125, 'thành': 126, 'bảo': 127, 'đại': 128, 'tự': 129, 'nhất': 130, 'vào': 131, 'chỉ': 132, 'xuyên': 133, 'rõ': 134, 'trọng': 135, 'trung': 136, 'vấn': 137, 'quả': 138, 'tận': 139, 'giá': 140, 'chị': 141, 'nhu': 142, 'em': 143, 'thời': 144, 'phù': 145, 'cấp': 146, 'môi': 147, 'chịu': 148, 'nhiệt': 149, 'sở': 150, 'hành': 151, 'ích': 152, 'mái': 153, 'thoải': 154, 'and': 155, 'hiệu': 156, 'đa': 157, 'cung': 158, 'toàn': 159, 'điều': 160, 'hiện': 161, 'lực': 162, 'hệ': 163, 'đã': 164, 'đạt': 165, 'kinh': 166, 'quyết': 167, 'giờ': 168, 'hội': 169, 'vật': 170, 'hỏi': 171, 'tìm': 172, 'liệu': 173, 'máy': 174, 'trí': 175, 'minh': 176, 'tinh': 177, 'dục': 178, 'hay': 179, 'khăn': 180, 'truyền': 181, 'pháp': 182, 'tư': 183, 'đánh': 184, 'từ': 185, 'tích': 186, 'thống': 187, 'dạng': 188, 'thư': 189, 'thần': 190, 'vụ': 191, 'cập': 192, 'an': 193, 'mà': 194, 'kết': 195, 'đảm': 196, 'vì': 197, 'ngành': 198, 'thú': 199, 'phương': 200, 'đối': 201, 'đó': 202, 'muốn': 203, 'kế': 204, 'như': 205, 'số': 206, 'độ': 207, 'nhiệm': 208, 'khóa': 209, 'cứu': 210, 'cực': 211, 'nhật': 212, 'quản': 213, 'hướng': 214, 'tuyệt': 215, 'nghiên': 216, 'vời': 217, 'biết': 218, 'dẫn': 219, 'rộng': 220, 'sử': 221, 'đây': 222, 'vị': 223, 'nhân': 224, 'lại': 225, 'sẵn': 226, 'đúng': 227, 'hài': 228, 'sẽ': 229, 'đáng': 230, 'nhà': 231, 'tiến': 232, 'ràng': 233, 'ở': 234, 'cả': 235, 'bản': 236, 'đội': 237, 'gia': 238, 'tương': 239, 'tác': 240, 'trách': 241, 'sàng': 242, 'tham': 243, 'cậu': 244, 'for': 245, 'lòng': 246, 'định': 247, 'nhau': 248, 'yêu': 249, 'curriculum': 250, 'vệ': 251, 'hứng': 252, 'lợi': 253, 'hoàn': 254, 'tôn': 255, 'chúng': 256, 'students': 257, 'phải': 258, 'tưởng': 259, 'khuôn': 260, 'dàng': 261, 'cận': 262, 'giao': 263, 'lời': 264, 'đều': 265, 'giữa': 266, 'phần': 267, 'áp': 268, 'trì': 269, 'chia': 270, 'facilities': 271, 'ăn': 272, 'nghề': 273, 'sống': 274, 'mở': 275, 'nghi': 276, 'thuyết': 277, 'chính': 278, 'nhận': 279, 'sẻ': 280, 'án': 281, 'chức': 282, 'sách': 283, 'huyết': 284, 'cùng': 285, 'khiến': 286, 'bao': 287, 'điểm': 288, 'đầu': 289, 'giữ': 290, 'bộ': 291, 'cuộc': 292, 'mê': 293, 'gì': 294, 'duy': 295, 'chăm': 296, 'nội': 297, 'chuẩn': 298, 'cải': 299, 'lĩnh': 300, 'tiêu': 301, 'bằng': 302, 'sạch': 303, 'dung': 304, 'liên': 305, 'đam': 306, 'nên': 307, 'viện': 308, 'to': 309, 'thật': 310, 'trở': 311, 'tiết': 312, 'nói': 313, 'tổ': 314, 'giỏi': 315, 'gây': 316, 'are': 317, 'nghe': 318, 'sức': 319, 'a': 320, 'nghệ': 321, 'thêm': 322, 'hữu': 323, 'vui': 324, 'sau': 325, 'chủ': 326, 'nhanh': 327, 'khích': 328, 'university': 329, 'phục': 330, 'dự': 331, 'luyện': 332, 'biệt': 333, 'câu': 334, 'dịch': 335, 'kiểm': 336, 'theo': 337, 'cố': 338, 'phong': 339, 'khoa': 340, 'đẹp': 341, 'đổi': 342, 'sâu': 343, 'kỳ': 344, 'nghĩ': 345, 'hòa': 346, 'chi': 347, 'chưa': 348, 'of': 349, 'thí': 350, 'đóng': 351, 'thuận': 352, 'kém': 353, 'khuyến': 354, 'đạo': 355, 'ngoại': 356, 'dựng': 357, 'linh': 358, 'has': 359, 'tiễn': 360, 'campus': 361, 'kiện': 362, 'xây': 363, 'nâng': 364, 'thuật': 365, 'phân': 366, 'phản': 367, 'chung': 368, 'hàng': 369, 'rèn': 370, 'tra': 371, 'mềm': 372, 'bổ': 373, 'đặt': 374, 'kiên': 375, 'từng': 376, 'góp': 377, 'cụ': 378, 'đang': 379, 'nào': 380, 'giãn': 381, 'cởi': 382, 'rằng': 383, 'mục': 384, 'hoặc': 385, 'đặc': 386, 'túc': 387, 'bố': 388, 'trị': 389, 'is': 390, 'gắng': 391, 'tiếng': 392, 'xe': 393, 'nghiêm': 394, 'nhìn': 395, 'tỉ': 396, 'lai': 397, 'phí': 398, 'lớn': 399, 'khí': 400, 'i': 401, 'cũng': 402, 'đáo': 403, 'gần': 404, 'chú': 405, 'đồ': 406, 'ngoài': 407, 'đi': 408, 'trải': 409, 'khá': 410, 'kiếm': 411, 'hình': 412, 'tất': 413, 'nhưng': 414, 'nơi': 415, 'bất': 416, 'ít': 417, 'độc': 418, 'tầm': 419, 'lắng': 420, 'thị': 421, 'gặp': 422, 'mỉ': 423, 'kích': 424, 'chỗ': 425, 'luận': 426, 'rãi': 427, 'xung': 428, 'mang': 429, 'mấy': 430, 'cũ': 431, 'quanh': 432, 'thoáng': 433, 'chuyện': 434, 'chán': 435, 'ngũ': 436, 'cá': 437, 'ký': 438, 'vẻ': 439, 'chiếu': 440, 'còn': 441, 'xác': 442, 'xử': 443, 'thảo': 444, 'trực': 445, 'tỏ': 446, 'hề': 447, 'thu': 448, 'lập': 449, 'giác': 450, 'lãnh': 451, 'chẳng': 452, 'vô': 453, 'do': 454, 'thắc': 455, 'mắc': 456, 'suy': 457, 'sắc': 458, 'thương': 459, 'chọn': 460, 'phú': 461, 'dụ': 462, 'thao': 463, 'mát': 464, 'ảnh': 465, 'bởi': 466, 'văn': 467, 'tăng': 468, 'lao': 469, 'chấp': 470, 'hóa': 471, 'hấp': 472, 'trả': 473, 'trên': 474, 'đường': 475, 'chóng': 476, 'ngồi': 477, 'huống': 478, 'yên': 479, 'in': 480, 'xanh': 481, 'nhẫn': 482, 'ví': 483, 'qua': 484, 'nhỏ': 485, 'hưởng': 486, 'mất': 487, 'xã': 488, 'đọc': 489, 'tượng': 490, 'thế': 491, 'tục': 492, 'xúc': 493, 'hết': 494, 'hạn': 495, 'sóc': 496, 'quốc': 497, 'sân': 498, 'universitys': 499, 'well': 500, 'cửa': 501, 'suốt': 502, 'hồi': 503, 'thái': 504, 'đòi': 505, 'tối': 506, 'chơi': 507, 'bắt': 508, 'khỏe': 509, 'cậy': 510, 'doanh': 511, 'uống': 512, 'cộng': 513, 'mặt': 514, 'vững': 515, 'tiên': 516, 'provides': 517, 'đem': 518, 'nghỉ': 519, 'lựa': 520, 'cẩn': 521, 'lạc': 522, 'mong': 523, 'mạnh': 524, 'nối': 525, 'thẳng': 526, 'đơn': 527, 'chu': 528, 'bỏ': 529, 'chàng': 530, 'ngày': 531, 'ngữ': 532, 'riêng': 533, 'good': 534, 'lỗi': 535, 'thay': 536, 'niệm': 537, 'chậm': 538, 'tĩnh': 539, 'chế': 540, 'nhiên': 541, 'khái': 542, 'phá': 543, 'ánh': 544, 'ninh': 545, 'thấu': 546, 'khuyên': 547, 'cường': 548, 'xếp': 549, 'giảm': 550, 'so': 551, 'trước': 552, 'đăng': 553, 'lịch': 554, 'khách': 555, 'vọng': 556, 'lúc': 557, 'nắm': 558, 'xa': 559, 'lên': 560, 'ghế': 561, 'nhàm': 562, 'phức': 563, 'âm': 564, 'buổi': 565, 'căng': 566, 'khô': 567, 'khan': 568, 'sai': 569, 'thận': 570, 'hào': 571, 'mắt': 572, 'cứ': 573, 'nó': 574, 'sắp': 575, 'dùng': 576, 'thi': 577, 'tệ': 578, 'ồn': 579, 'nguyên': 580, 'niềm': 581, 'giới': 582, 'mối': 583, 'kỷ': 584, 'mỗi': 585, 'mẻ': 586, 'mức': 587, 'xu': 588, 'tạp': 589, 'diện': 590, 'chắc': 591, 'ấn': 592, 'bè': 593, 'chân': 594, 'chỉnh': 595, 'đức': 596, 'vượt': 597, 'dành': 598, 'lạnh': 599, 'phẩm': 600, 'that': 601, 'wifi': 602, 'điện': 603, 'hoạch': 604, 'dài': 605, 'may': 606, 'sung': 607, 'hước': 608, 'trưởng': 609, 'nước': 610, 'xá': 611, 'xuất': 612, 'ưu': 613, 'kính': 614, 'nổi': 615, 'ổn': 616, 'nguồn': 617, 'khảo': 618, 'kịp': 619, 'bàn': 620, 'họp': 621, 'sát': 622, 'báo': 623, 'tiền': 624, 'with': 625, 'thanh': 626, 'mắn': 627, 'bảng': 628, 'chuyển': 629, 'cảnh': 630, 'nàng': 631, 'ai': 632, 'thứ': 633, 'nữa': 634, 'lưỡng': 635, 'nỗ': 636, 'cạnh': 637, 'helpful': 638, 'khám': 639, 'nghĩa': 640, 'đèn': 641, 'ngôn': 642, 'trò': 643, 'tới': 644, 'thất': 645, 'hắn': 646, 'giản': 647, 'cười': 648, 'tranh': 649, 'bình': 650, 'kia': 651, 'lưu': 652, 'nay': 653, 'nền': 654, 'chặt': 655, 'chẽ': 656, 'feel': 657, 'quên': 658, 'trời': 659, 'phạm': 660, 'thách': 661, 'đựng': 662, 'nhạy': 663, 'cái': 664, 'yếu': 665, 'quy': 666, 'logic': 667, 'biện': 668, 'phép': 669, 'internet': 670, 'ào': 671, 'gợi': 672, 'ngừng': 673, 'ngơi': 674, 'ơn': 675, 'hơi': 676, 'bày': 677, 'lạ': 678, 'sao': 679, 'nhắc': 680, 'giàu': 681, 'hạnh': 682, 'đợi': 683, 'chật': 684, 'phúc': 685, 'tuyến': 686, 'learning': 687, 'by': 688, 'soát': 689, 'sản': 690, 'đông': 691, 'ngắn': 692, 'thấp': 693, 'trao': 694, 'trau': 695, 'tử': 696, 'lâu': 697, 'giám': 698, 'tươi': 699, 'xem': 700, 'kĩ': 701, 'khoá': 702, 'rối': 703, 'ngon': 704, 'đời': 705, 'chữa': 706, 'đón': 707, 'đôi': 708, 'appreciate': 709, 'tải': 710, 'nóng': 711, 'đỗ': 712, 'hứa': 713, 'khắc': 714, 'dồi': 715, 'hẹp': 716, 'cứng': 717, 'bên': 718, 'courses': 719, 'tảng': 720, 'viết': 721, 'sửa': 722, 'nếu': 723, 'loại': 724, 'đoàn': 725, 'ngưỡng': 726, 'mộ': 727, 'kiệm': 728, 'bụng': 729, 'cân': 730, 'bạch': 731, 'trân': 732, 'phàn': 733, 'nàn': 734, 'thúc': 735, 'trễ': 736, 'tổng': 737, 'tràn': 738, 'quý': 739, 'họa': 740, 'quyền': 741, 'on': 742, 'lầm': 743, 'am': 744, 'facility': 745, 'phiền': 746, 'đắn': 747, 'research': 748, 'mệt': 749, 'mỏi': 750, 'like': 751, 'mạng': 752, 'lab': 753, 'thử': 754, 'at': 755, 'truy': 756, 'đoạn': 757, 'trai': 758, 'đột': 759, 'hút': 760, 'academic': 761, 'study': 762, 'kẻ': 763, 'phụ': 764, 'lành': 765, 'khai': 766, 'biểu': 767, 'needs': 768, 'con': 769, 'luật': 770, 'nhẹn': 771, 'lười': 772, 'opportunities': 773, 'tòa': 774, 'chắn': 775, 'range': 776, 'trạng': 777, 'địa': 778, 'ban': 779, 'càng': 780, 'nhạt': 781, 'đắt': 782, 'bóng': 783, 'đẩy': 784, 'thủ': 785, 'dựa': 786, 'bẩn': 787, 'chờ': 788, 'hồn': 789, 'lệ': 790, 'bổng': 791, 'mật': 792, 'căn': 793, 'accommodating': 794, 'nhẹ': 795, 'khéo': 796, 'trúc': 797, 'lần': 798, 'mến': 799, 'tín': 800, 'tiềm': 801, 'trích': 802, 'di': 803, 'nguyện': 804, 'sôi': 805, 'practical': 806, 'their': 807, 'bền': 808, 'chứa': 809, 'lấy': 810, 'lẫn': 811, 'đoán': 812, 'sợ': 813, 'encourages': 814, 'thạo': 815, 'móc': 816, 'cuốn': 817, 'ngủ': 818, 'thang': 819, 'đứng': 820, 'thì': 821, 'tẻ': 822, 'program': 823, 'dữ': 824, 'cống': 825, 'hiến': 826, 'kể': 827, 'miễn': 828, 'sót': 829, 'khía': 830, 'tuy': 831, 'nghị': 832, 'tò': 833, 'mò': 834, 'dõi': 835, 'hại': 836, 'chí': 837, 'dù': 838, 'hỏng': 839, 'chạp': 840, 'ngại': 841, 'nhàng': 842, 'cây': 843, 'tránh': 844, 'đuổi': 845, 'léo': 846, 'xấu': 847, 'phê': 848, 'ông': 849, 'tuyển': 850, 'diễn': 851, 'lặp': 852, 'gũi': 853, 'thiệu': 854, 'lo': 855, 'chả': 856, 'việt': 857, 'biếng': 858, 'dưỡng': 859, 'cấu': 860, 'đổ': 861, 'buồn': 862, 'lí': 863, 'variety': 864, 'current': 865, 'chê': 866, 'bai': 867, 'prepares': 868, 'tốc': 869, 'quán': 870, 'đá': 871, 'phấn': 872, 'coi': 873, 'giọng': 874, 'photocopy': 875, 'nhớ': 876, 'rác': 877, 'gián': 878, 'offers': 879, 'bí': 880, 'center': 881, 'offered': 882, 'lắm': 883, 'thiểu': 884, 'thiên': 885, 'trái': 886, 'món': 887, 'chứng': 888, 'provide': 889, 'điệu': 890, 'đích': 891, 'tắc': 892, 'comfortable': 893, 'đạp': 894, 'bát': 895, 'nấu': 896, 'lãng': 897, 'mẽ': 898, 'how': 899, 'skills': 900, 'xét': 901, 'vài': 902, 'thoại': 903, 'sang': 904, 'kiểu': 905, 'hạ': 906, 'ưa': 907, 'ép': 908, 'xứng': 909, 'cắt': 910, 'buộc': 911, 'sư': 912, 'quen': 913, 'within': 914, 'phía': 915, 'trội': 916, 'wi': 917, 'fi': 918, 'impressed': 919, 'quảng': 920, 'clean': 921, 'khắt': 922, 'khe': 923, 'rườm': 924, 'nhạc': 925, 'khoảng': 926, 'easy': 927, 'up': 928, 'cáo': 929, 'lôi': 930, 'hy': 931, 'cà': 932, 'hoãn': 933, 'tay': 934, 'nhờ': 935, 'chội': 936, 'cãi': 937, 'development': 938, 'stress': 939, 'ấm': 940, 'giả': 941, 'khởi': 942, 'classrooms': 943, 'can': 944, 'dở': 945, 'toán': 946, 'gồm': 947, 'vận': 948, 'óc': 949, 'chạy': 950, 'community': 951, 'bại': 952, 'student': 953, 'danh': 954, 'chứ': 955, 'tuệ': 956, 'future': 957, 'tốn': 958, 'phối': 959, 'hảo': 960, 'đấu': 961, '–': 962, 'tựu': 963, 'tầng': 964, 'useful': 965, 'vậy': 966, 'dịu': 967, 'ẩm': 968, 'sớm': 969, 'xin': 970, 'cổ': 971, 'vi': 972, 'gọn': 973, '\\u200b\\u200bcủa': 974, 'ái': 975, 'ghét': 976, 'web': 977, 'gìn': 978, 'suất': 979, 'adequate': 980, 'it': 981, 'đỏ': 982, 'hậu': 983, 'hầu': 984, 'phán': 985, 'bén': 986, 'rà': 987, 'muộn': 988, 'date': 989, 'mua': 990, 'tố': 991, 'mô': 992, 'năm': 993, 'chấm': 994, 'hồ': 995, 'promotes': 996, 'available': 997, 'y': 998, 'tồi': 999, 'all': 1000, 'trống': 1001, 'thác': 1002, 'hoà': 1003, 'đúc': 1004, 'convenient': 1005, 'chiếm': 1006, 'mâu': 1007, 'sổ': 1008, 'nỗi': 1009, 'giành': 1010, 'lông': 1011, 'buýt': 1012, 'environment': 1013, 'lỡ': 1014, 'lệch': 1015, 'khỏi': 1016, 'equipped': 1017, 'world': 1018, 'relevant': 1019, 'trends': 1020, 'tuần': 1021, 'strong': 1022, 'bãi': 1023, 'miệng': 1024, 'bước': 1025, 'thuộc': 1026, 'lễ': 1027, '1': 1028, 'faculty': 1029, 'thù': 1030, 'duyên': 1031, 'thỉu': 1032, 'khuyết': 1033, 'ham': 1034, 'nản': 1035, 'hi': 1036, 'different': 1037, 'gàng': 1038, 'uy': 1039, 'đình': 1040, 'quát': 1041, 'hãi': 1042, 'who': 1043, 'work': 1044, 'personal': 1045, 'growth': 1046, 'modern': 1047, 'nặng': 1048, 'lộ': 1049, 'tòi': 1050, 'khơi': 1051, 'thô': 1052, 'bật': 1053, 'gỡ': 1054, 'among': 1055, 'sắm': 1056, 'ngặt': 1057, 'chiến': 1058, 'bạo': 1059, 'đãng': 1060, 'parking': 1061, 'mừng': 1062, 'support': 1063, 'vai': 1064, 'kí': 1065, 'tủ': 1066, 'tùy': 1067, 'bận': 1068, 'rộn': 1069, '\\u200b\\u200bthức': 1070, 'quầy': 1071, 'trắng': 1072, 'areas': 1073, 'maintained': 1074, 'lừa': 1075, 'dối': 1076, 'giễu': 1077, 'thắn': 1078, 'have': 1079, 'thuẫn': 1080, 'tri': 1081, 'studies': 1082, 'bếp': 1083, 'bối': 1084, 'access': 1085, 'materials': 1086, 'cài': 1087, 'ngân': 1088, 'hoá': 1089, 'excellent': 1090, 'nam': 1091, 'conducive': 1092, 'tắt': 1093, 'bán': 1094, 'satisfactory': 1095, 'labs': 1096, 'ngay': 1097, 'tức': 1098, 'rích': 1099, 'real': 1100, 'lăng': 1101, 'overall': 1102, 'hiểm': 1103, 'foundation': 1104, 'khinh': 1105, 'tai': 1106, 'diverse': 1107, 'safe': 1108, 'thỏa': 1109, 'giống': 1110, 'karaoke': 1111, 'tennis': 1112, 'thuốc': 1113, 'designed': 1114, 'nét': 1115, 'dáng': 1116, 'gym': 1117, 'bác': 1118, 'lối': 1119, 'tật': 1120, 'mẩn': 1121, 'bầu': 1122, 'trẻ': 1123, 'gắn': 1124, 'nhầm': 1125, 'ngạc': 1126, 'rời': 1127, 'hoan': 1128, 'emphasis': 1129, 'đo': 1130, 'ác': 1131, 'innovation': 1132, 'services': 1133, 'tấm': 1134, 'bạc': 1135, 'independent': 1136, 'technology': 1137, 'always': 1138, 'nghèo': 1139, 'from': 1140, 'nề': 1141, 'lỗ': 1142, 'suôn': 1143, 'huynh': 1144, 'đẳng': 1145, 'feedback': 1146, 'course': 1147, 'be': 1148, 'lược': 1149, 'bơi': 1150, 'xảy': 1151, 'ủng': 1152, 'hộ': 1153, 'practices': 1154, 'lang': 1155, 'chuộng': 1156, 'khắp': 1157, 'ngờ': 1158, 'khiển': 1159, 'options': 1160, 'khoan': 1161, 'challenges': 1162, 'online': 1163, 'system': 1164, 'biến': 1165, 'giặt': 1166, 'khoe': 1167, 'khoang': 1168, 'nhập': 1169, 'thưởng': 1170, 'security': 1171, 'vườn': 1172, 'mãn': 1173, 'đậu': 1174, 'professional': 1175, 'meet': 1176, 'rắc': 1177, 'career': 1178, 'kéo': 1179, 'ngăn': 1180, 'nắp': 1181, 'critical': 1182, 'thinking': 1183, 'vv': 1184, 'mực': 1185, 'necessary': 1186, 'vẫn': 1187, 'impressive': 1188, 'collaboration': 1189, 'nạt': 1190, 'kín': 1191, 'global': 1192, 'đàm': 1193, 'ample': 1194, 'emphasizes': 1195, 'giai': 1196, 'vở': 1197, 'health': 1198, 'teamwork': 1199, 'allowing': 1200, 'making': 1201, 'sơ': 1202, 'fosters': 1203, 'problem': 1204, 'solving': 1205, 'giật': 1206, 'rooms': 1207, 'enable': 1208, 'đất': 1209, 'bus': 1210, 'trôi': 1211, 'thuê': 1212, 'industry': 1213, 'legal': 1214, 'email': 1215, 'tán': 1216, 'loạn': 1217, 'nhã': 1218, 'top': 1219, 'notch': 1220, 'includes': 1221, 'sustainable': 1222, 'video': 1223, 'careers': 1224, 'nguy': 1225, 'mùi': 1226, 'inclusive': 1227, 'located': 1228, 'sút': 1229, 'trầm': 1230, 'nhằm': 1231, 'khôn': 1232, 'ngoan': 1233, 'ngược': 1234, 'lùi': 1235, 'mãi': 1236, 'tuân': 1237, 'phóng': 1238, 'staff': 1239, 'thăng': 1240, 'thụ': 1241, 'vinh': 1242, 'gió': 1243, 'mẫn': 1244, 'đứt': 1245, 'programs': 1246, 'cater': 1247, 'góc': 1248, 'chiều': 1249, 'vẹn': 1250, 'hân': 1251, 'ngắt': 1252, 'providing': 1253, 'nhở': 1254, 'tỉnh': 1255, 'táo': 1256, 'lường': 1257, 'tường': 1258, 'sàn': 1259, 'clinic': 1260, 'cam': 1261, 'mẫu': 1262, 'buồng': 1263, 'wide': 1264, 'đặn': 1265, 'hiển': 1266, 'organized': 1267, 'space': 1268, 'open': 1269, 'communication': 1270, 'mặc': 1271, 'khoản': 1272, 'its': 1273, 'experiences': 1274, 'dậy': 1275, 'language': 1276, 'marketing': 1277, 'creativity': 1278, 'khiếu': 1279, '24': 1280, '7': 1281, 'cương': 1282, 'trông': 1283, 'found': 1284, 'biên': 1285, 'job': 1286, 'theoretical': 1287, 'knowledge': 1288, 'hổ': 1289, 'ôn': 1290, 'tuổi': 1291, 'đãi': 1292, 'cỏi': 1293, 'multiple': 1294, 'comprehensive': 1295, 'slide': 1296, 'uyên': 1297, 'outside': 1298, 'hư': 1299, 'lẽ': 1300, 'tiếc': 1301, 'hát': 1302, 'experience': 1303, 'kì': 1304, 'use': 1305, 'kỉ': 1306, 'internships': 1307, 'bực': 1308, 'our': 1309, 'ensuring': 1310, 'hụt': 1311, 'cù': 1312, 'thuần': 1313, 'yoga': 1314, 'computer': 1315, 'bức': 1316, 'giận': 1317, 'cultural': 1318, 'mưa': 1319, 'cặn': 1320, 'kẽ': 1321, 'accessible': 1322, 'bá': 1323, 'rồi': 1324, 'xì': 1325, 'supports': 1326, 'international': 1327, 'my': 1328, 'lũy': 1329, 'dám': 1330, 'nhộn': 1331, 'success': 1332, 'giường': 1333, 'tớ': 1334, 'thôi': 1335, 'ám': 1336, 'sủa': 1337, 'lam': 1338, 'dinh': 1339, 'through': 1340, 'transportation': 1341, 'rạc': 1342, 'spacious': 1343, 'thằng': 1344, 'interdisciplinary': 1345, 'khen': 1346, 'cán': 1347, 'thảm': 1348, 'trốn': 1349, 'rounded': 1350, 'mùa': 1351, 'ước': 1352, 'around': 1353, 'phận': 1354, 'backgrounds': 1355, 'lùng': 1356, 'nắng': 1357, 'resources': 1358, 'sense': 1359, 'tim': 1360, 'engage': 1361, 'đen': 1362, 'giang': 1363, 'dining': 1364, 'kiêu': 1365, 'dòng': 1366, 'ba': 1367, 'during': 1368, 'khối': 1369, 'sports': 1370, 'nhiễm': 1371, 'great': 1372, 'đêm': 1373, 'thưa': 1374, 'trạm': 1375, 'provided': 1376, 'chiêu': 1377, 'ngùng': 1378, 'athletic': 1379, 'nhảy': 1380, 'chuốt': 1381, 'garden': 1382, 'ga': 1383, 'assessments': 1384, 'progress': 1385, 'applications': 1386, 'dần': 1387, 'ti': 1388, 'bậc': 1389, 'quí': 1390, 'vắng': 1391, 'major': 1392, 'bỉ': 1393, 'ghi': 1394, 'chép': 1395, 'rổ': 1396, 'huấn': 1397, 'tân': 1398, 'friendly': 1399, 'vội': 1400, 'hoa': 1401, 'sĩ': 1402, 'tách': 1403, 'cưỡng': 1404, 'dưới': 1405, 'perspectives': 1406, 'thải': 1407, 'visa': 1408, 'điển': 1409, 'deadline': 1410, 'interests': 1411, 'mộng': 1412, 'giving': 1413, 'back': 1414, 'thà': 1415, 'entrepreneurship': 1416, 'quay': 1417, 'quality': 1418, 'lái': 1419, 'electives': 1420, 'projects': 1421, 'self': 1422, 'responsible': 1423, 'nhiễu': 1424, 'chuỗi': 1425, 'stocked': 1426, 'cuối': 1427, 'quiet': 1428, 'break': 1429, 'hoài': 1430, 'chút': 1431, 'dọa': 1432, 'điên': 1433, 'chèn': 1434, 'bé': 1435, 'us': 1436, 'đùa': 1437, 'ty': 1438, 'thở': 1439, 'several': 1440, 'activities': 1441, 'ẩn': 1442, 'navigate': 1443, 'thoát': 1444, 'kept': 1445, 'responsive': 1446, 'trệ': 1447, 'rẻ': 1448, 'lướt': 1449, 'mảng': 1450, 'tuỳ': 1451, 'gái': 1452, 'mờ': 1453, 'functional': 1454, 'hoang': 1455, 'lượt': 1456, 'nữ': 1457, 'soạn': 1458, 'objectives': 1459, 'giở': 1460, 'updated': 1461, 'reflect': 1462, 'sảnh': 1463, 'camera': 1464, 'lắp': 1465, 'engaging': 1466, 'bệnh': 1467, 'phu': 1468, 'vé': 1469, 'structured': 1470, 'recreational': 1471, 'lộn': 1472, 'ngạo': 1473, 'mạn': 1474, 'grounds': 1475, 'beautiful': 1476, 'disabilities': 1477, 'think': 1478, 'box': 1479, 'báu': 1480, 'prayer': 1481, 'room': 1482, 'flexible': 1483, 'enough': 1484, 'allow': 1485, 'lương': 1486, 'sen': 1487, 'kiềm': 1488, 'thổi': 1489, 'triết': 1490, 'rẽ': 1491, 'lưới': 1492, 'điệp': 1493, 'cáu': 1494, 'appropriate': 1495, 'beautifully': 1496, 'atmosphere': 1497, 'nở': 1498, 'nụ': 1499, 'đắc': 1500, 'đám': 1501, 'game': 1502, 'giếng': 1503, 'khói': 1504, 'efficient': 1505, 'cánh': 1506, 'equipment': 1507, 'condition': 1508, 'khoái': 1509, 'follow': 1510, 'business': 1511, 'thước': 1512, 'inquiry': 1513, 'nhai': 1514, 'phó': 1515, 'cợt': 1516, 'não': 1517, 'tổn': 1518, 'nhạo': 1519, 'lội': 1520, 'building': 1521, 'aligns': 1522, 'loa': 1523, 'hời': 1524, 'hợt': 1525, 'săn': 1526, 'trượt': 1527, 'other': 1528, 'loát': 1529, 'qui': 1530, 'nghẽn': 1531, 'toilet': 1532, 'đứa': 1533, 'chụp': 1534, 'phỏng': 1535, 'sufficient': 1536, 'màu': 1537, 'extended': 1538, 'hours': 1539, 'utilize': 1540, 'dày': 1541, 'experiential': 1542, 'disabled': 1543, 'bữa': 1544, 'thượng': 1545, 'tàn': 1546, 'đàn': 1547, 'tuỵ': 1548, 'decent': 1549, 'vờ': 1550, 'vũ': 1551, 'trữ': 1552, 'đố': 1553, 'kỵ': 1554, 'ức': 1555, 'tọa': 1556, 'thiệp': 1557, 'vehicles': 1558, 'further': 1559, 'commitment': 1560, 'hỗn': 1561, 'chảnh': 1562, 'tắm': 1563, 'phổ': 1564, 'u': 1565, 'vướng': 1566, 'theater': 1567, 'group': 1568, 'knowledgeable': 1569, 'management': 1570, 'lứa': 1571, 'understanding': 1572, 'gain': 1573, 'lạm': 1574, 'resource': 1575, 'bội': 1576, 'tựa': 1577, 'chiếc': 1578, 'plenty': 1579, 'gò': 1580, 'bó': 1581, 'lưng': 1582, 'mix': 1583, 'social': 1584, 'life': 1585, 'cản': 1586, 'tăm': 1587, 'conveniently': 1588, 'amenities': 1589, 'thập': 1590, 'hỏa': 1591, 'vàng': 1592, 'thả': 1593, 'tỏa': 1594, 'effectively': 1595, 'mỉa': 1596, 'mai': 1597, 'phi': 1598, 'hoại': 1599, 'bừa': 1600, 'nhằn': 1601, 'đương': 1602, 'đảo': 1603, 'counseling': 1604, 'mental': 1605, 'developments': 1606, 'field': 1607, 'clb': 1608, 'chăng': 1609, 'sạn': 1610, 'makes': 1611, 'dây': 1612, 'needed': 1613, 'nại': 1614, 'cross': 1615, 'dốt': 1616, 'accessibility': 1617, 'relax': 1618, 'mải': 1619, 'rắm': 1620, 'canteen': 1621, 'cắm': 1622, 'trại': 1623, 'cỏ': 1624, 'bớt': 1625, 'art': 1626, 'hiền': 1627, 'fit': 1628, 'challenging': 1629, 'opportunity': 1630, 'bike': 1631, 'nộp': 1632, 'network': 1633, 'suited': 1634, 'conference': 1635, 'quite': 1636, 'diversity': 1637, 'inclusivity': 1638, 'sustainability': 1639, 'ngông': 1640, 'cuồng': 1641, 'environmental': 1642, '\\u200b\\u200bkhác': 1643, 'và': 1644, 'hè': 1645, 'đốc': 1646, 'take': 1647, 'chừng': 1648, 'mơ': 1649, 'kèm': 1650, 'active': 1651, 'trương': 1652, 'song': 1653, 'such': 1654, 'as': 1655, 'library': 1656, 'tụy': 1657, 'effective': 1658, 'healthy': 1659, 'giấy': 1660, 'lửa': 1661, 'trêu': 1662, 'nạp': 1663, 'food': 1664, 'gửi': 1665, 'leadership': 1666, 'màn': 1667, 'thiệt': 1668, 'nature': 1669, 'uyển': 1670, 'most': 1671, 'vừa': 1672, 'thớt': 1673, 'musical': 1674, 'artistic': 1675, 'chữ': 1676, 'chảy': 1677, 'tóm': 1678, 'interact': 1679, 'professionals': 1680, 'advice': 1681, 'cộ': 1682, 'nằm': 1683, 'chín': 1684, 'bánh': 1685, 'mì': 1686, 'lấn': 1687, 'át': 1688, 'phủ': 1689, 'science': 1690, 'experiments': 1691, 'ngượng': 1692, 'chau': 1693, 'merger': 1694, 'thẩm': 1695, 'mỹ': 1696, 'measure': 1697, 'performance': 1698, 'prioritizes': 1699, 'living': 1700, 'kê': 1701, 'livestream': 1702, 'nhăng': 1703, 'adequately': 1704, 'dọc': 1705, 'regardless': 1706, 'thẻ': 1707, 'đâm': 1708, 'bịt': 1709, 'area': 1710, 'mại': 1711, 'nghiệt': 1712, 'khiếm': 1713, 'rập': 1714, '40': 1715, '3': 1716, 'members': 1717, 'approachable': 1718, 'hầm': 1719, 'hòi': 1720, 'ngớt': 1721, 'hổi': 1722, 'marginalized': 1723, 'communities': 1724, 'chém': 1725, 'service': 1726, 'hiếm': 1727, 'music': 1728, 'khớp': 1729, 'thờ': 1730, 'placed': 1731, 'low': 1732, 'income': 1733, 'individuals': 1734, 'gói': 1735, 'talent': 1736, 'đốn': 1737, 'guồng': 1738, 'dã': 1739, 'bay': 1740, 'chở': 1741, 'tần': 1742, 'housing': 1743, 'need': 1744, 'lõng': 1745, 'or': 1746, 'reflection': 1747, 'quấy': 1748, 'rầy': 1749, 'mưu': 1750, 'maintaining': 1751, 'tỷ': 1752, 'scholarships': 1753, 'financial': 1754, 'aid': 1755, 'logictic': 1756, 'bathrooms': 1757, 'nướng': 1758, 'bbq': 1759, 'phái': 1760, 'khẩu': 1761, 'kêu': 1762, 'ca': 1763, 'rơi': 1764, 'nhâm': 1765, 'nhi': 1766, 'lounge': 1767, 'nice': 1768, 'studying': 1769, 'transparency': 1770, 'mạo': 1771, 'satisfied': 1772, 'luân': 1773, 'situations': 1774, 'giửa': 1775, 'administrative': 1776, 'khẩn': 1777, 'hà': 1778, 'extracurricular': 1779, 'promoting': 1780, 'nhòa': 1781, 'trắc': 1782, 'tạm': 1783, 'continuously': 1784, 'improving': 1785, 'fair': 1786, 'objective': 1787, 'chửi': 1788, 'chênh': 1789, 'mài': 1790, 'kháo': 1791, 'gật': 1792, 'view': 1793, 'serviceable': 1794, 'thorough': 1795, 'researched': 1796, 'does': 1797, 'combining': 1798, 'bướng': 1799, 'bỉnh': 1800, 'achieve': 1801, 'phiên': 1802, 'toà': 1803, 'viện…': 1804, 'chào': 1805, 'hách': 1806, 'tặng': 1807, 'kênh': 1808, 'cồng': 1809, 'kềnh': 1810, 'regularly': 1811, 'best': 1812, 'thought': 1813, 'provoking': 1814, 'cars': 1815, 'chốt': 1816, 'đạc': 1817, 'xộn': 1818, 'trúng': 1819, 'cleanliness': 1820, 'chồng': 1821, 'dạn': 1822, 'dĩ': 1823, 'journalism': 1824, 'ỏi': 1825, 'thấm': 1826, 'súc': 1827, 'critically': 1828, 'practice': 1829, 'faith': 1830, 'developed': 1831, 'enables': 1832, 'remotely': 1833, 'lọc': 1834, 'pursue': 1835, 'phút': 1836, 'giây': 1837, 'xỉ': 1838, 'sỹ': 1839, 'phũ': 1840, 'phàng': 1841, 'lồng': 1842, 'ghép': 1843, 'nghênh': 1844, 'ủi': 1845, 'giày': 1846, 'dép': 1847, 'trọn': 1848, 'dao': 1849, 'khủng': 1850, 'hoảng': 1851, 'trít': 1852, 'kèn': 1853, 'application': 1854, 'concepts': 1855, 'dọn': 1856, 'trăm': 1857, 'xoáy': 1858, 'lật': 1859, 'gắt': 1860, 'levels': 1861, 'landscaped': 1862, 'relaxing': 1863, 'bida': 1864, 'sẹo': 1865, 'sánh': 1866, 'trưng': 1867, 'kẹt': 1868, 'dạo': 1869, 'nham': 1870, 'nhãn': 1871, 'khiếp': 1872, 'times': 1873, 'cúng': 1874, 'tháng': 1875, 'laptop': 1876, 'đệm': 1877, 'allows': 1878, 'individual': 1879, 'exploration': 1880, 'discovery': 1881, 'anytime': 1882, 'common': 1883, 'informative': 1884, 'thoughtfully': 1885, 'planned': 1886, 'mượt': 1887, 'nạn': 1888, 'nghiêp': 1889, 'measures': 1890, 'place': 1891, 'ensure': 1892, 'safety': 1893, 'core': 1894, 'competencies': 1895, 'workshops': 1896, 'resume': 1897, 'searching': 1898, 'giơi': 1899, 'đâu': 1900, 'rigorous': 1901, 'hạng': 1902, 'hủy': 1903, 'standards': 1904, 'hung': 1905, 'miệt': 1906, 'thợ': 1907, 'patin': 1908, 'tuyết': 1909, 'par': 1910, 'institutions': 1911, 'thai': 1912, 'tutoring': 1913, 'rủi': 1914, 'ro': 1915, 'dị': 1916, 'đoan': 1917, 'quyến': 1918, 'rũ': 1919, 'cấm': 1920, 'rớt': 1921, 'laboratory': 1922, 'cử': 1923, 'châm': 1924, 'chọc': 1925, 'giơ': 1926, 'n': 1927, 'lan': 1928, 'man': 1929, 'đồn': 1930, 'bóc': 1931, 'chánh': 1932, 'large': 1933, 'windows': 1934, 'natural': 1935, 'light': 1936, 'creating': 1937, 'industrial': 1938, 'various': 1939, 'paths': 1940, 'khán': 1941, 'organizations': 1942, 'hands': 1943, 'tiểu': 1944, 'tồn': 1945, 'laboratories': 1946, 'scientific': 1947, 'tivi': 1948, 'hệt': 1949, 'tiệm': 1950, 'tiệc': 1951, 'chừa': 1952, 'chat': 1953, 'ren': 1954, 'positively': 1955, 'impacts': 1956, 'goals': 1957, 'addresses': 1958, 'important': 1959, 'issues': 1960, 'standard': 1961, 'connecting': 1962, 'potential': 1963, 'mentors': 1964, 'dang': 1965, 'collaborative': 1966, 'bám': 1967, 'thốn': 1968, 'registration': 1969, 'thèm': 1970, 'hăng': 1971, 'hái': 1972, 'ngang': 1973, 'shopping': 1974, 'retail': 1975, 'prepare': 1976, 'chần': 1977, 'chừ': 1978, 'chăn': 1979, 'public': 1980, 'xô': 1981, 'xát': 1982, 'chó': 1983, 'hả': 1984, 'map': 1985, 'newcomers': 1986, 'rửa': 1987, 'nhấn': 1988, 'khịa': 1989, 'rữa': 1990, 'bookstores': 1991, 'plethora': 1992, 'required': 1993, 'textbooks': 1994, 'hãy': 1995, 'lau': 1996, 'chùi': 1997, 'ngu': 1998, 'xuẩn': 1999, 'stage': 2000, 'perfect': 2001, 'ráo': 2002, 'riết': 2003, 'thục': 2004, 'qualified': 2005, 'phạt': 2006, 'nuối': 2007, 'báng': 2008, 'mẹo': 2009, 'experienced': 2010, 'instructors': 2011, 'energy': 2012, 'reducing': 2013, 'carbon': 2014, 'footprint': 2015, 'gấp': 2016, 'gáp': 2017, 'khôi': 2018, 'exchange': 2019, 'trọ': 2020, 'chống': 2021, 'tóc': 2022, 'nails': 2023, 'ventilated': 2024, 'co': 2025, 'op': 2026, 'cối': 2027, 'lành…': 2028, 'nhắm': 2029, 'xé': 2030, 'cỡi': 2031, 'duyệt': 2032, 'balances': 2033, 'tắp': 2034, 'nập': 2035, 'cafeteria': 2036, 'reasonably': 2037, 'priced': 2038, 'láo': 2039, 'dừng': 2040, 'tụi': 2041, 'trá': 2042, 'đàng': 2043, 'hoàng': 2044, 'tuyên': 2045, 'toả': 2046, 'empaty': 2047, 'supply': 2048, 'water': 2049, 'electricity': 2050, 'outages': 2051, 'rare': 2052, 'lầu': 2053, 'balance': 2054, 'both': 2055, 'aspects': 2056, 'tấn': 2057, 'rào': 2058, 'xuống': 2059, 'tools': 2060, 'essential': 2061, 'múa': 2062, 'offices': 2063, 'gốc': 2064, 'gà': 2065, 'hoạn': 2066, 'transport': 2067, 'links': 2068, 'commute': 2069, 'lẩn': 2070, 'education': 2071, 'lỏng': 2072, 'assist': 2073, 'xạ': 2074, 'laser': 2075, 'yến': 2076, 'cơm': 2077, 'getting': 2078, 'town': 2079, 'ngợi': 2080, 'gẽ': 2081, 'vu': 2082, 'khống': 2083, 'auditorium': 2084, 'bộn': 2085, 'resourced': 2086, 'embracing': 2087, 'cultures': 2088, 'tộc': 2089, 'dè': 2090, 'bỉu': 2091, 'bão': 2092, 'google': 2093, 'taught': 2094, 'professors': 2095, 'lòa': 2096, 'syllabus': 2097, 'clear': 2098, 'incorporates': 2099, 'latest': 2100, 'băng': 2101, 'training': 2102, 'explore': 2103, 'waste': 2104, 'workforce': 2105, 'networking': 2106, 'kén': 2107, 'dơ': 2108, 'thuỷ': 2109, 'độn': 2110, 'lơ': 2111, 'đễnh': 2112, 'gượng': 2113, 'cám': 2114, 'dỗ': 2115, 'trật': 2116, 'tidy': 2117, 'which': 2118, 'pleasant': 2119, 'hổng': 2120, 'guidance': 2121, 'when': 2122, 'case': 2123, 'đút': 2124, 'khâm': 2125, 'multifaceted': 2126, 'nát': 2127, 'availability': 2128, 'shaded': 2129, 'unwind': 2130, 'chúc': 2131, 'printing': 2132, 'copying': 2133, 'dạ': 2134, 'dân': 2135, 'tệp': 2136, 'instructional': 2137, 'used': 2138, 'nén': 2139, 'studio': 2140, 'creative': 2141, 'cạn': 2142, 'kiệt': 2143, 'đe': 2144, 'constantly': 2145, 'customized': 2146, 'each': 2147, 'lấp': 2148, 'phố': 2149, 'but': 2150, 'still': 2151, 'manageable': 2152, 'nổ': 2153, 'racks': 2154, 'throughout': 2155, 'encourage': 2156, 'ride': 2157, 'bệ': 2158, 'thắng': 2159, 'grateful': 2160, 'alumni': 2161, 'pursuits': 2162, 'meeting': 2163, 'túy': 2164, 'xao': 2165, 'nhãng': 2166, 'hàm': 2167, 'đừng': 2168, 'balanced': 2169, 'terms': 2170, 'workload': 2171, 'difficulty': 2172, 'level': 2173, 'recognizes': 2174, 'importance': 2175, 'chủng': 2176, 'đục': 2177, 'hằng': 2178, 'belonging': 2179, 'toa': 2180, 'lét': 2181, 'recycling': 2182, 'rạp': 2183, 'phim': 2184, 'nhẽo': 2185, 'gương': 2186, 'chìm': 2187, 'rệt': 2188, 'ngỗ': 2189, 'nghịch': 2190, 'bời': 2191, 'lận': 2192, 'niên': 2193, 'vụng': 2194, 'tội': 2195, 'quỷ': 2196, 'software': 2197, 'consistently': 2198, 'reviews': 2199, 'improves': 2200, 'met': 2201, 'được': 2202, 'tín': 2203, 'nhiệm': 2204, 'trọng': 2205, 'bởi': 2206, 'chọe': 2207, 'adaptive': 2208, 'changing': 2209, 'societal': 2210, 'mãnh': 2211, 'liệt': 2212, 'cướp': 2213, 'nhe': 2214, 'răng': 2215, 'employment': 2216, 'tỉa': 2217, 'volunteer': 2218, 'bịa': 2219, 'chước': 2220, 'lõi': 2221, 'welcome': 2222, 'đoạt': 2223, 'siêu': 2224, 'led': 2225, 'lots': 2226, 'travel': 2227, 'car': 2228, 'park': 2229, 'sài': 2230, 'nhút': 2231, 'nhát': 2232, 'củng': 2233, 'air': 2234, 'conditioned': 2235, 'especially': 2236, 'hot': 2237, 'seasons': 2238, 'grants': 2239, 'sảng': 2240, 'ụy': 2241, 'mị': 2242, 'kẻo': 2243, 'sofa': 2244, 'ảm': 2245, 'đạm': 2246, 'nấm': 2247, 'dứt': 2248, 'khoát': 2249, 'content': 2250, 'presented': 2251, 'interactive': 2252, 'way': 2253, 'khát': 2254, 'khao': 2255, 'dằn': 2256, 'trét': 2257, 'ngấy': 2258, 'green': 2259, 'gaming': 2260, 'fun': 2261, 'ownership': 2262, 'based': 2263, 'vớ': 2264, 'vẩn': 2265, 'phiếm': 2266, 'xướng': 2267, 'socialization': 2268, 'khép': 2269, 'đống': 2270, 'tàng': 2271, 'welcoming': 2272, 'pro': 2273, 'nang': 2274, 'workplace': 2275, 'usability': 2276, 'phớt': 2277, 'lờ': 2278, 'dặn': 2279, 'vĩ': 2280, 'quãng': 2281, 'medical': 2282, 'wellness': 2283, 'rảnh': 2284, 'xy': 2285, 'rùa': 2286, 'lách': 2287, 'xong': 2288, 'ô': 2289, 'dac': 2290, 'contact': 2291, 'mic': 2292, 'usa': 2293, 'phô': 2294, 'hùng': 2295, 'silence': 2296, 'require': 2297, 'đốt': 2298, 'cháy': 2299, 'gạo': 2300, 'thoả': 2301, 'atm': 2302, 'live': 2303, 'lifestyle': 2304, 'fitness': 2305, 'classes': 2306, 'mỉm': 2307, 'hộp': 2308, 'ghen': 2309, 'tỵ': 2310, 'thừa': 2311, 'thãi': 2312, 'hôi': 2313, 'thối': 2314, 'gọi': 2315, 'nãi': 2316, 'locker': 2317, 'accommodate': 2318, 'styles': 2319, 'lạn': 2320, 'bikemot': 2321, 'cẩu': 2322, 'quỹ': 2323, 'chợ': 2324, 'exam': 2325, 'weeks': 2326, 'ae': 2327, 'scan': 2328, 'lounges': 2329, 'giấc': 2330, 'decorated': 2331, 'holidays': 2332, 'chuông': 2333, 'move': 2334, 'easily': 2335, 'outdoor': 2336, 'rưởi': 2337, 'whiteboards': 2338, 'projectors': 2339, 'keeping': 2340, 'bách': 2341, 'collection': 2342, 'books': 2343, 'phơi': 2344, 'quần': 2345, 'áo': 2346, 'thăm': 2347, 'quân': 2348, 'cư': 2349, 'vươn': 2350, 'gổ': 2351, 'ùn': 2352, 'vân': 2353, 'già': 2354, 'there': 2355, 'serve': 2356, 'reasonable': 2357, 'prices': 2358, 'caters': 2359, 'gắm': 2360, 'thỉnh': 2361, 'thoảng': 2362, 'gân': 2363, 'ethical': 2364, 'giấu': 2365, 'giếm': 2366, 'market': 2367, 'vã': 2368, 'đau': 2369, 'holding': 2370, 'events': 2371, 'meetings': 2372, 'dorms': 2373, 'secure': 2374, 'là': 2375, 'nghỉm': 2376, 'connection': 2377, 'across': 2378, 'reliable': 2379, 'quất': 2380, 'citizenship': 2381, 'roles': 2382, 'mè': 2383, 'tên': 2384, 'wheelchair': 2385, 'thuẩn': 2386, 'thói': 2387, 'ửng': 2388, 'đen…': 2389, 'promote': 2390, 'làng': 2391, 'maintenance': 2392, 'elective': 2393, 'choose': 2394, 'trail': 2395, 'enthusiasts': 2396, 'tờ': 2397, 'high': 2398, 'speed': 2399, 'platform': 2400, 'advocacy': 2401, 'kháng': 2402, 'chât': 2403, 'vay': 2404, 'trú': 2405, 'nánh': 2406, 'cốt': 2407, 'chuyến': 2408, 'extension': 2409, 'outlets': 2410, 'charging': 2411, 'devices': 2412, 'đião': 2413, 'toalet': 2414, 'no': 2415, 'complaints': 2416, 'about': 2417, 'make': 2418, 'out': 2419, 'bồi': 2420, 'khang': 2421, 'intellectually': 2422, 'stimulating': 2423, 'offer': 2424, 'khoảnh': 2425, 'đợt': 2426, 'mớ': 2427, 'tress': 2428, 'thơ': 2429, 'trớ': 2430, 'lung': 2431, 'tung': 2432, 'requirements': 2433, 'supporting': 2434, 'one': 2435, 'another': 2436, 'journey': 2437, 'trăn': 2438, 'hiếp': 2439, 'đà': 2440, 'máu': 2441, 'lạch': 2442, 'cạch': 2443, 'offline': 2444, 'uể': 2445, 'oải': 2446, 'lụt': 2447, 'exchanging': 2448, 'schools': 2449, 'soft': 2450, 'teaches': 2451, 'creatively': 2452, 'deluaruận': 2453, 'admissions': 2454, 'selection': 2455, 'khung': 2456, 'traveling': 2457, 'disciplinary': 2458, 'approaches': 2459, 'liều': 2460, 'lẻ': 2461, 'ngô': 2462, 'sét': 2463, 'psychology': 2464, 'atms': 2465, 'cash': 2466, 'dắt': 2467, '\\u200b\\u200bxây': 2468, 'tàu': 2469}\n"]}],"source":["tokenizer = Tokenizer(num_words=5000, oov_token=\"<OOV>\")\n","tokenizer.fit_on_texts(df_train['sentence'])\n","word_index = tokenizer.word_index\n","print(word_index)"]},{"cell_type":"markdown","source":["# Thực hiện gắn nhãn và chuyển về vector\n"],"metadata":{"id":"R7YfPt22FcVW"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"3vRTA31JFqw4"},"outputs":[],"source":["training_sequences = tokenizer.texts_to_sequences(df_train['sentence'])\n","training_padded = pad_sequences(training_sequences, maxlen=20, padding='post', truncating='post')\n","\n","validating_sequences = tokenizer.texts_to_sequences(df_val['sentence'])\n","validating_padded = pad_sequences(validating_sequences, maxlen=20, padding='post', truncating='post')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":303,"status":"ok","timestamp":1694962173669,"user":{"displayName":"9370 _ Phạm Thiện Tài","userId":"17496006235026682420"},"user_tz":-420},"id":"4mcTUNwqKNyw","outputId":"85d78136-f636-4600-99f8-243ac99d694a"},"outputs":[{"data":{"text/plain":["array([[ 237,  436,  127, ...,   62,   53,    0],\n","       [  66,  499, 1674, ...,    0,    0,    0],\n","       [ 200,  182,   10, ...,    0,    0,    0],\n","       ...,\n","       [  39,  141,  164, ...,   11,    0,    0],\n","       [  40,   21,    4, ...,    0,    0,    0],\n","       [  11,  104,  629, ...,   11,    0,    0]], dtype=int32)"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["training_padded"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1694962175586,"user":{"displayName":"9370 _ Phạm Thiện Tài","userId":"17496006235026682420"},"user_tz":-420},"id":"nI6iszMuKQGY","outputId":"ca770d54-dff8-4dff-ddd1-4ff298223fda"},"outputs":[{"data":{"text/plain":["array([[ 81, 125, 170, ...,   0,   0,   0],\n","       [267, 372,   4, ...,   0,   0,   0],\n","       [ 13,  11,  87, ...,  22, 160, 346],\n","       ...,\n","       [ 87, 117, 358, ...,   0,   0,   0],\n","       [ 34,  32,   7, ...,   0,   0,   0],\n","       [ 39,  32,   9, ...,  93,  19, 107]], dtype=int32)"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["validating_padded"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":302,"status":"ok","timestamp":1694962177832,"user":{"displayName":"9370 _ Phạm Thiện Tài","userId":"17496006235026682420"},"user_tz":-420},"id":"bAEVccqADsmK","outputId":"721104f6-c6c9-4b81-d321-59eb830d8da7"},"outputs":[{"data":{"text/plain":["0       negative\n","1        neutral\n","2        neutral\n","3       positive\n","4        neutral\n","          ...   \n","2031     neutral\n","2032     neutral\n","2033    negative\n","2034    positive\n","2035    positive\n","Name: sentiment, Length: 10180, dtype: object"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["pd.concat((df_train['sentiment'],df_val['sentiment']), axis=0)"]},{"cell_type":"markdown","source":["# Gắn nhãn cho cột \"setiment\""],"metadata":{"id":"0uDt5ksDFxhJ"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":74},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1695213592259,"user":{"displayName":"9370 _ Phạm Thiện Tài","userId":"17496006235026682420"},"user_tz":-420},"id":"UKxTZ9nwC1N7","outputId":"118b43c6-6d41-4a8b-a064-c5b968fc0962"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["LabelEncoder()"],"text/html":["<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LabelEncoder</label><div class=\"sk-toggleable__content\"><pre>LabelEncoder()</pre></div></div></div></div></div>"]},"metadata":{},"execution_count":6}],"source":["le = LabelEncoder()\n","le.fit(pd.concat((df_train['sentiment'],df_val['sentiment']), axis=0))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xtulfMZ1_LtM"},"outputs":[],"source":["df_train['sentiment'] = le.transform(df_train['sentiment'])\n","df_val['sentiment'] = le.transform(df_val['sentiment'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ImqwsgxX92gM"},"outputs":[],"source":["df = pd.concat((df_train,df_val), axis=0).sample(42)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nqpsw2a28iAs"},"outputs":[],"source":["df['sentiment'] = le.transform(df['sentiment'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PmiRKbotkNfV"},"outputs":[],"source":["training_padded = np.array(training_padded)\n","validating_padded = np.array(validating_padded)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3PcXpzjCrhIt"},"outputs":[],"source":["# text_input = tf.keras.layers.Input(shape=(), dtype=tf.string)\n","\n","# preprocessor = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n","# encoder_inputs = preprocessor(df_train['sentence'])\n","\n","# encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-128_A-2/2\",trainable=True)\n","# outputs = encoder(df_train['sentiment'])\n","\n","# pooled_output = outputs[\"pooled_output\"]    # [batch_size, 128].\n","# sequence_output = outputs[\"sequence_output\"]    # [batch_size, seq_length, 128]."]},{"cell_type":"markdown","source":["# Train trên LSTM model\n","\n","- Tạo 1 lớp Embedding để chuyển ma trận chữ về các vector.\n","- Tạo 1 lớp LSTM model để train.\n","- Tạo 4 lớp ẩn (Dense) có chứa những hàm kích hoạt, ở đây là hàm \"relu\".\n","- Tạo lớp cuối cùng có sử dụng hàm \"sigmoid\" để phân biệt câu và dự đoán câu.\n","- Có thể tăng hoặc giảm số lượng lớp Dense. Tùy thuộc vào mô hình. Càng nhiều lớp thì mô hình càng nặng. Tương tự như lớp, thì số node trong lớp có thể tăng hoặc giảm."],"metadata":{"id":"Dt0qrghcHMOG"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":629,"status":"ok","timestamp":1695046772143,"user":{"displayName":"9370 _ Phạm Thiện Tài","userId":"17496006235026682420"},"user_tz":-420},"id":"mtail8REKn30","outputId":"1e85f968-7c8d-4090-c533-68223b4d749f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding (Embedding)       (None, None, 16)          160000    \n","                                                                 \n"," lstm (LSTM)                 (None, 64)                20736     \n","                                                                 \n"," dense_4 (Dense)             (None, 128)               8320      \n","                                                                 \n"," dense_5 (Dense)             (None, 64)                8256      \n","                                                                 \n"," dense_6 (Dense)             (None, 32)                2080      \n","                                                                 \n"," dense_7 (Dense)             (None, 16)                528       \n","                                                                 \n"," dense_8 (Dense)             (None, 3)                 51        \n","                                                                 \n","=================================================================\n","Total params: 199971 (781.14 KB)\n","Trainable params: 199971 (781.14 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}],"source":["vocab_size = 10000\n","embedding_dim = 16\n","max_length = 20\n","training_size = 20000\n","\n","\n","model = tf.keras.Sequential([\n","    tf.keras.layers.Embedding(vocab_size, embedding_dim),\n","    #tf.keras.layers.GlobalAveragePooling1D(),\n","    tf.keras.layers.LSTM(64),\n","    #TFBertModel.from_pretrained(\"albert-base-v2\"),\n","    tf.keras.layers.Dense(128, activation='relu'),\n","    tf.keras.layers.Dense(64, activation='relu'),\n","    tf.keras.layers.Dense(32, activation='relu'),\n","    tf.keras.layers.Dense(16, activation='relu'),\n","    tf.keras.layers.Dense(3, activation='sigmoid')\n","])\n","model.summary()\n","\n","model.compile(loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False),optimizer=tf.keras.optimizers.Adam(),metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"UtU8KWXyeiiw","outputId":"d8296525-e45c-4940-dd34-402c84a49213"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/100\n","255/255 - 20s - loss: 0.7414 - accuracy: 0.6181 - val_loss: 0.5326 - val_accuracy: 0.7593 - 20s/epoch - 78ms/step\n","Epoch 2/100\n","255/255 - 3s - loss: 0.4730 - accuracy: 0.7818 - val_loss: 0.4932 - val_accuracy: 0.7868 - 3s/epoch - 13ms/step\n","Epoch 3/100\n","255/255 - 2s - loss: 0.4015 - accuracy: 0.8194 - val_loss: 0.4652 - val_accuracy: 0.7981 - 2s/epoch - 9ms/step\n","Epoch 4/100\n","255/255 - 2s - loss: 0.3717 - accuracy: 0.8358 - val_loss: 0.4686 - val_accuracy: 0.8070 - 2s/epoch - 8ms/step\n","Epoch 5/100\n","255/255 - 3s - loss: 0.3531 - accuracy: 0.8439 - val_loss: 0.5038 - val_accuracy: 0.7755 - 3s/epoch - 12ms/step\n","Epoch 6/100\n","255/255 - 2s - loss: 0.3330 - accuracy: 0.8540 - val_loss: 0.4816 - val_accuracy: 0.8035 - 2s/epoch - 7ms/step\n","Epoch 7/100\n","255/255 - 2s - loss: 0.3236 - accuracy: 0.8567 - val_loss: 0.5204 - val_accuracy: 0.8006 - 2s/epoch - 6ms/step\n","Epoch 8/100\n","255/255 - 2s - loss: 0.3114 - accuracy: 0.8630 - val_loss: 0.5615 - val_accuracy: 0.8065 - 2s/epoch - 8ms/step\n","Epoch 9/100\n","255/255 - 2s - loss: 0.3029 - accuracy: 0.8671 - val_loss: 0.5294 - val_accuracy: 0.8084 - 2s/epoch - 6ms/step\n","Epoch 10/100\n","255/255 - 2s - loss: 0.2934 - accuracy: 0.8718 - val_loss: 0.5329 - val_accuracy: 0.8026 - 2s/epoch - 10ms/step\n","Epoch 11/100\n","255/255 - 2s - loss: 0.2872 - accuracy: 0.8741 - val_loss: 0.5472 - val_accuracy: 0.7981 - 2s/epoch - 6ms/step\n","Epoch 12/100\n","255/255 - 2s - loss: 0.2808 - accuracy: 0.8770 - val_loss: 0.5823 - val_accuracy: 0.7996 - 2s/epoch - 10ms/step\n","Epoch 13/100\n","255/255 - 2s - loss: 0.2775 - accuracy: 0.8765 - val_loss: 0.5760 - val_accuracy: 0.8104 - 2s/epoch - 10ms/step\n","Epoch 14/100\n","255/255 - 2s - loss: 0.2603 - accuracy: 0.8874 - val_loss: 0.6374 - val_accuracy: 0.8006 - 2s/epoch - 6ms/step\n","Epoch 15/100\n","255/255 - 2s - loss: 0.2587 - accuracy: 0.8863 - val_loss: 0.5616 - val_accuracy: 0.8060 - 2s/epoch - 7ms/step\n","Epoch 16/100\n","255/255 - 2s - loss: 0.2465 - accuracy: 0.8958 - val_loss: 0.6755 - val_accuracy: 0.7996 - 2s/epoch - 6ms/step\n","Epoch 17/100\n","255/255 - 2s - loss: 0.2448 - accuracy: 0.8970 - val_loss: 0.6347 - val_accuracy: 0.8070 - 2s/epoch - 7ms/step\n","Epoch 18/100\n","255/255 - 2s - loss: 0.2384 - accuracy: 0.8972 - val_loss: 0.6790 - val_accuracy: 0.8070 - 2s/epoch - 6ms/step\n","Epoch 19/100\n","255/255 - 1s - loss: 0.2261 - accuracy: 0.9016 - val_loss: 0.6582 - val_accuracy: 0.8021 - 1s/epoch - 6ms/step\n","Epoch 20/100\n","255/255 - 2s - loss: 0.2171 - accuracy: 0.9059 - val_loss: 0.7637 - val_accuracy: 0.7898 - 2s/epoch - 8ms/step\n","Epoch 21/100\n","255/255 - 3s - loss: 0.2144 - accuracy: 0.9068 - val_loss: 0.7122 - val_accuracy: 0.8006 - 3s/epoch - 10ms/step\n","Epoch 22/100\n","255/255 - 2s - loss: 0.2179 - accuracy: 0.9075 - val_loss: 0.6823 - val_accuracy: 0.8099 - 2s/epoch - 8ms/step\n","Epoch 23/100\n","255/255 - 2s - loss: 0.2047 - accuracy: 0.9118 - val_loss: 0.7403 - val_accuracy: 0.7917 - 2s/epoch - 6ms/step\n","Epoch 24/100\n","255/255 - 2s - loss: 0.1961 - accuracy: 0.9138 - val_loss: 0.7509 - val_accuracy: 0.8016 - 2s/epoch - 8ms/step\n","Epoch 25/100\n","255/255 - 3s - loss: 0.1872 - accuracy: 0.9181 - val_loss: 0.8162 - val_accuracy: 0.7922 - 3s/epoch - 10ms/step\n","Epoch 26/100\n","255/255 - 2s - loss: 0.1965 - accuracy: 0.9169 - val_loss: 0.6622 - val_accuracy: 0.8035 - 2s/epoch - 6ms/step\n","Epoch 27/100\n","255/255 - 2s - loss: 0.1880 - accuracy: 0.9181 - val_loss: 0.7420 - val_accuracy: 0.7942 - 2s/epoch - 7ms/step\n","Epoch 28/100\n","255/255 - 2s - loss: 0.1777 - accuracy: 0.9229 - val_loss: 0.7511 - val_accuracy: 0.7883 - 2s/epoch - 9ms/step\n","Epoch 29/100\n","255/255 - 2s - loss: 0.1777 - accuracy: 0.9220 - val_loss: 0.8430 - val_accuracy: 0.8021 - 2s/epoch - 7ms/step\n","Epoch 30/100\n","255/255 - 2s - loss: 0.1881 - accuracy: 0.9193 - val_loss: 0.7029 - val_accuracy: 0.7888 - 2s/epoch - 7ms/step\n","Epoch 31/100\n","255/255 - 1s - loss: 0.1789 - accuracy: 0.9224 - val_loss: 0.8396 - val_accuracy: 0.7986 - 1s/epoch - 6ms/step\n","Epoch 32/100\n","255/255 - 1s - loss: 0.1648 - accuracy: 0.9288 - val_loss: 0.8663 - val_accuracy: 0.7883 - 1s/epoch - 6ms/step\n","Epoch 33/100\n","255/255 - 2s - loss: 0.1596 - accuracy: 0.9299 - val_loss: 0.8784 - val_accuracy: 0.7834 - 2s/epoch - 7ms/step\n","Epoch 34/100\n","255/255 - 1s - loss: 0.1543 - accuracy: 0.9330 - val_loss: 0.8317 - val_accuracy: 0.7898 - 1s/epoch - 6ms/step\n","Epoch 35/100\n","255/255 - 1s - loss: 0.1554 - accuracy: 0.9323 - val_loss: 0.9692 - val_accuracy: 0.7962 - 1s/epoch - 6ms/step\n","Epoch 36/100\n","255/255 - 2s - loss: 0.1461 - accuracy: 0.9343 - val_loss: 0.9268 - val_accuracy: 0.7839 - 2s/epoch - 9ms/step\n","Epoch 37/100\n","255/255 - 3s - loss: 0.1472 - accuracy: 0.9347 - val_loss: 0.9472 - val_accuracy: 0.7888 - 3s/epoch - 10ms/step\n","Epoch 38/100\n","255/255 - 2s - loss: 0.1419 - accuracy: 0.9376 - val_loss: 0.9906 - val_accuracy: 0.7844 - 2s/epoch - 7ms/step\n","Epoch 39/100\n","255/255 - 2s - loss: 0.1365 - accuracy: 0.9377 - val_loss: 0.9659 - val_accuracy: 0.7819 - 2s/epoch - 7ms/step\n","Epoch 40/100\n","255/255 - 2s - loss: 0.1375 - accuracy: 0.9368 - val_loss: 0.9968 - val_accuracy: 0.7814 - 2s/epoch - 6ms/step\n","Epoch 41/100\n","255/255 - 2s - loss: 0.1325 - accuracy: 0.9402 - val_loss: 0.9371 - val_accuracy: 0.7800 - 2s/epoch - 8ms/step\n","Epoch 42/100\n","255/255 - 2s - loss: 0.1256 - accuracy: 0.9430 - val_loss: 0.9628 - val_accuracy: 0.7785 - 2s/epoch - 7ms/step\n","Epoch 43/100\n","255/255 - 1s - loss: 0.1218 - accuracy: 0.9478 - val_loss: 1.0377 - val_accuracy: 0.7873 - 1s/epoch - 5ms/step\n","Epoch 44/100\n","255/255 - 3s - loss: 0.1155 - accuracy: 0.9457 - val_loss: 1.0058 - val_accuracy: 0.7706 - 3s/epoch - 10ms/step\n","Epoch 45/100\n","255/255 - 2s - loss: 0.1286 - accuracy: 0.9436 - val_loss: 1.0225 - val_accuracy: 0.7819 - 2s/epoch - 9ms/step\n","Epoch 46/100\n","255/255 - 2s - loss: 0.1104 - accuracy: 0.9531 - val_loss: 1.0655 - val_accuracy: 0.7834 - 2s/epoch - 6ms/step\n","Epoch 47/100\n","255/255 - 1s - loss: 0.0986 - accuracy: 0.9571 - val_loss: 1.0954 - val_accuracy: 0.7839 - 1s/epoch - 6ms/step\n","Epoch 48/100\n","255/255 - 1s - loss: 0.1119 - accuracy: 0.9508 - val_loss: 1.1216 - val_accuracy: 0.7785 - 1s/epoch - 6ms/step\n","Epoch 49/100\n","255/255 - 2s - loss: 0.0942 - accuracy: 0.9608 - val_loss: 1.2281 - val_accuracy: 0.7809 - 2s/epoch - 7ms/step\n","Epoch 50/100\n","255/255 - 2s - loss: 0.0982 - accuracy: 0.9625 - val_loss: 1.0722 - val_accuracy: 0.7765 - 2s/epoch - 6ms/step\n","Epoch 51/100\n","255/255 - 2s - loss: 0.0934 - accuracy: 0.9616 - val_loss: 1.1942 - val_accuracy: 0.7800 - 2s/epoch - 7ms/step\n","Epoch 52/100\n","255/255 - 2s - loss: 0.0860 - accuracy: 0.9659 - val_loss: 1.2970 - val_accuracy: 0.7824 - 2s/epoch - 7ms/step\n","Epoch 53/100\n","255/255 - 2s - loss: 0.0908 - accuracy: 0.9661 - val_loss: 1.0858 - val_accuracy: 0.7800 - 2s/epoch - 8ms/step\n","Epoch 54/100\n","255/255 - 2s - loss: 0.0939 - accuracy: 0.9653 - val_loss: 1.1311 - val_accuracy: 0.7854 - 2s/epoch - 9ms/step\n","Epoch 55/100\n","255/255 - 2s - loss: 0.0925 - accuracy: 0.9661 - val_loss: 1.2274 - val_accuracy: 0.7854 - 2s/epoch - 6ms/step\n","Epoch 56/100\n","255/255 - 1s - loss: 0.0858 - accuracy: 0.9684 - val_loss: 1.3025 - val_accuracy: 0.7839 - 1s/epoch - 6ms/step\n","Epoch 57/100\n","255/255 - 2s - loss: 0.0729 - accuracy: 0.9736 - val_loss: 1.3437 - val_accuracy: 0.7790 - 2s/epoch - 6ms/step\n","Epoch 58/100\n","255/255 - 1s - loss: 0.0738 - accuracy: 0.9741 - val_loss: 1.3680 - val_accuracy: 0.7741 - 1s/epoch - 6ms/step\n","Epoch 59/100\n","255/255 - 2s - loss: 0.0808 - accuracy: 0.9720 - val_loss: 1.1861 - val_accuracy: 0.7819 - 2s/epoch - 7ms/step\n","Epoch 60/100\n","255/255 - 2s - loss: 0.0766 - accuracy: 0.9727 - val_loss: 1.2525 - val_accuracy: 0.7854 - 2s/epoch - 6ms/step\n","Epoch 61/100\n","255/255 - 2s - loss: 0.0685 - accuracy: 0.9777 - val_loss: 1.1846 - val_accuracy: 0.7746 - 2s/epoch - 8ms/step\n","Epoch 62/100\n","255/255 - 3s - loss: 0.0621 - accuracy: 0.9785 - val_loss: 1.4116 - val_accuracy: 0.7755 - 3s/epoch - 13ms/step\n","Epoch 63/100\n","255/255 - 2s - loss: 0.0643 - accuracy: 0.9770 - val_loss: 1.4205 - val_accuracy: 0.7746 - 2s/epoch - 8ms/step\n","Epoch 64/100\n","255/255 - 2s - loss: 0.0627 - accuracy: 0.9775 - val_loss: 1.4525 - val_accuracy: 0.7785 - 2s/epoch - 8ms/step\n","Epoch 65/100\n","255/255 - 3s - loss: 0.0641 - accuracy: 0.9768 - val_loss: 1.3964 - val_accuracy: 0.7809 - 3s/epoch - 10ms/step\n","Epoch 66/100\n","255/255 - 2s - loss: 0.0532 - accuracy: 0.9842 - val_loss: 1.4632 - val_accuracy: 0.7746 - 2s/epoch - 8ms/step\n","Epoch 67/100\n","255/255 - 3s - loss: 0.0528 - accuracy: 0.9818 - val_loss: 1.5787 - val_accuracy: 0.7750 - 3s/epoch - 11ms/step\n","Epoch 68/100\n","255/255 - 3s - loss: 0.0558 - accuracy: 0.9819 - val_loss: 1.3940 - val_accuracy: 0.7770 - 3s/epoch - 12ms/step\n","Epoch 69/100\n","255/255 - 3s - loss: 0.0456 - accuracy: 0.9837 - val_loss: 1.7385 - val_accuracy: 0.7780 - 3s/epoch - 11ms/step\n","Epoch 70/100\n","255/255 - 1s - loss: 0.0587 - accuracy: 0.9789 - val_loss: 1.3882 - val_accuracy: 0.7760 - 1s/epoch - 6ms/step\n","Epoch 71/100\n","255/255 - 1s - loss: 0.0529 - accuracy: 0.9822 - val_loss: 1.4446 - val_accuracy: 0.7878 - 1s/epoch - 6ms/step\n","Epoch 72/100\n","255/255 - 2s - loss: 0.0467 - accuracy: 0.9848 - val_loss: 1.5877 - val_accuracy: 0.7849 - 2s/epoch - 6ms/step\n","Epoch 73/100\n","255/255 - 2s - loss: 0.0430 - accuracy: 0.9859 - val_loss: 1.7622 - val_accuracy: 0.7795 - 2s/epoch - 6ms/step\n","Epoch 74/100\n","255/255 - 1s - loss: 0.0423 - accuracy: 0.9875 - val_loss: 1.5322 - val_accuracy: 0.7726 - 1s/epoch - 6ms/step\n","Epoch 75/100\n","255/255 - 2s - loss: 0.0462 - accuracy: 0.9835 - val_loss: 1.5836 - val_accuracy: 0.7795 - 2s/epoch - 9ms/step\n","Epoch 76/100\n","255/255 - 2s - loss: 0.0394 - accuracy: 0.9871 - val_loss: 1.5580 - val_accuracy: 0.7677 - 2s/epoch - 8ms/step\n","Epoch 77/100\n","255/255 - 2s - loss: 0.0413 - accuracy: 0.9875 - val_loss: 1.5259 - val_accuracy: 0.7859 - 2s/epoch - 8ms/step\n","Epoch 78/100\n","255/255 - 3s - loss: 0.0315 - accuracy: 0.9902 - val_loss: 1.8107 - val_accuracy: 0.7760 - 3s/epoch - 10ms/step\n","Epoch 79/100\n","255/255 - 2s - loss: 0.0449 - accuracy: 0.9853 - val_loss: 1.5300 - val_accuracy: 0.7898 - 2s/epoch - 8ms/step\n","Epoch 80/100\n","255/255 - 2s - loss: 0.0418 - accuracy: 0.9867 - val_loss: 1.3542 - val_accuracy: 0.7780 - 2s/epoch - 9ms/step\n","Epoch 81/100\n","255/255 - 3s - loss: 0.0302 - accuracy: 0.9905 - val_loss: 1.6415 - val_accuracy: 0.7755 - 3s/epoch - 10ms/step\n","Epoch 82/100\n","255/255 - 3s - loss: 0.0288 - accuracy: 0.9904 - val_loss: 1.6794 - val_accuracy: 0.7839 - 3s/epoch - 13ms/step\n","Epoch 83/100\n","255/255 - 3s - loss: 0.0280 - accuracy: 0.9913 - val_loss: 1.7967 - val_accuracy: 0.7785 - 3s/epoch - 12ms/step\n","Epoch 84/100\n","255/255 - 2s - loss: 0.0348 - accuracy: 0.9889 - val_loss: 1.7777 - val_accuracy: 0.7839 - 2s/epoch - 8ms/step\n","Epoch 85/100\n","255/255 - 3s - loss: 0.0329 - accuracy: 0.9885 - val_loss: 1.8276 - val_accuracy: 0.7800 - 3s/epoch - 12ms/step\n","Epoch 86/100\n","255/255 - 2s - loss: 0.0324 - accuracy: 0.9886 - val_loss: 1.8319 - val_accuracy: 0.7800 - 2s/epoch - 8ms/step\n","Epoch 87/100\n","255/255 - 3s - loss: 0.0248 - accuracy: 0.9925 - val_loss: 1.5954 - val_accuracy: 0.7755 - 3s/epoch - 11ms/step\n","Epoch 88/100\n","255/255 - 3s - loss: 0.0304 - accuracy: 0.9904 - val_loss: 1.4930 - val_accuracy: 0.7809 - 3s/epoch - 11ms/step\n","Epoch 89/100\n","255/255 - 3s - loss: 0.0267 - accuracy: 0.9907 - val_loss: 1.6504 - val_accuracy: 0.7765 - 3s/epoch - 11ms/step\n","Epoch 90/100\n","255/255 - 2s - loss: 0.0263 - accuracy: 0.9913 - val_loss: 1.7209 - val_accuracy: 0.7760 - 2s/epoch - 8ms/step\n","Epoch 91/100\n","255/255 - 2s - loss: 0.0270 - accuracy: 0.9910 - val_loss: 1.8586 - val_accuracy: 0.7692 - 2s/epoch - 8ms/step\n","Epoch 92/100\n","255/255 - 2s - loss: 0.0199 - accuracy: 0.9936 - val_loss: 2.0328 - val_accuracy: 0.7731 - 2s/epoch - 8ms/step\n","Epoch 93/100\n","255/255 - 2s - loss: 0.0274 - accuracy: 0.9910 - val_loss: 1.7990 - val_accuracy: 0.7662 - 2s/epoch - 6ms/step\n","Epoch 94/100\n","255/255 - 2s - loss: 0.0187 - accuracy: 0.9942 - val_loss: 1.8278 - val_accuracy: 0.7746 - 2s/epoch - 6ms/step\n","Epoch 95/100\n","255/255 - 2s - loss: 0.0298 - accuracy: 0.9915 - val_loss: 1.8107 - val_accuracy: 0.7687 - 2s/epoch - 9ms/step\n","Epoch 96/100\n","255/255 - 2s - loss: 0.0254 - accuracy: 0.9910 - val_loss: 1.8080 - val_accuracy: 0.7721 - 2s/epoch - 9ms/step\n","Epoch 97/100\n","255/255 - 2s - loss: 0.0211 - accuracy: 0.9940 - val_loss: 1.9785 - val_accuracy: 0.7760 - 2s/epoch - 6ms/step\n","Epoch 98/100\n","255/255 - 1s - loss: 0.0199 - accuracy: 0.9929 - val_loss: 1.8949 - val_accuracy: 0.7805 - 1s/epoch - 6ms/step\n","Epoch 99/100\n","255/255 - 1s - loss: 0.0296 - accuracy: 0.9923 - val_loss: 1.8761 - val_accuracy: 0.7824 - 1s/epoch - 6ms/step\n","Epoch 100/100\n","255/255 - 1s - loss: 0.0248 - accuracy: 0.9929 - val_loss: 1.7394 - val_accuracy: 0.7770 - 1s/epoch - 6ms/step\n"]}],"source":["history = model.fit(training_padded, df_train['sentiment'].values, epochs = 100, validation_data=(validating_padded, df_val['sentiment'].values), verbose=2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hw3rxHtm1Uqx"},"outputs":[],"source":["##########################################################################################################################################"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6470,"status":"ok","timestamp":1695216431370,"user":{"displayName":"9370 _ Phạm Thiện Tài","userId":"17496006235026682420"},"user_tz":-420},"id":"FN_eTncY2h58","outputId":"88075027-7fa3-4fe2-b11b-a5e7d163f39f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tensorflow_text\n","  Downloading tensorflow_text-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_text) (0.14.0)\n","Requirement already satisfied: tensorflow<2.14,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_text) (2.13.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (23.5.26)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (0.4.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (0.2.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (1.57.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (3.9.0)\n","Requirement already satisfied: keras<2.14,>=2.13.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (2.13.1)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (16.0.6)\n","Requirement already satisfied: numpy<=1.24.3,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (1.23.5)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (23.1)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (1.16.0)\n","Requirement already satisfied: tensorboard<2.14,>=2.13 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (2.13.0)\n","Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (2.13.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (2.3.0)\n","Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (4.5.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (1.15.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (0.33.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.14,>=2.13.0->tensorflow_text) (0.41.2)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (3.4.4)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (2.31.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (0.7.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (2.3.7)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (5.3.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (2023.7.22)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (2.1.3)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (3.2.2)\n","Installing collected packages: tensorflow_text\n","Successfully installed tensorflow_text-2.13.0\n"]}],"source":["pip install tensorflow_text"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r5Bq14p22kJu"},"outputs":[],"source":["import tensorflow_text as text"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":136,"referenced_widgets":["3edbc834d4bc48ffab0394ddb712ff7c","2426f6af287b4738930f1c191cc29137","d565ede754cf4cf5a076d542863ce995","687b220d15854ed39cfc8430122d47a6","a53deacb41324cfbad017a249ace602d","cd18866eb83642fda9777ce42dd05143","c088c0a2651e42ee9c9823004910619d","5c5db40a71a24f92a9a9309555c19a1a","f11061e4314b417284fb327c3f3d0cb2","14ab10f1dc904573847ce43fb40f5cdb","ec2e261203b549048f7199bd6396a401","60224e5ce378433b8007f7e979e71f81","052ca36bd8a14c4a916c01fe3bb71760","e8f85f531de0488bacc428e0ea9900ea","7e742605a70945e19d245068dd5c8607","dcccf55628f148448aa455778e1da65f","5941aa4415364146a527d92a60d08ac4","f4cc2f5383b94491a67c0d83738756eb","9f329ab401dd48cf9f6a03fed5ec015d","0ac25e2183b94e5b923c0a9e5f9333f3","ab415fcfdfb640b6886924c6317f9abd","cfa74d591d314ae0ad57783544a6bf98"]},"executionInfo":{"elapsed":10937,"status":"ok","timestamp":1695095200667,"user":{"displayName":"9370 _ Phạm Thiện Tài","userId":"17496006235026682420"},"user_tz":-420},"id":"uSSh9K221m1Q","outputId":"3a65ee27-e3d9-44a3-a4d6-38994ee35bf1"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3edbc834d4bc48ffab0394ddb712ff7c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"60224e5ce378433b8007f7e979e71f81"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["bert_base = transformers.AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\")"]},{"cell_type":"markdown","source":["# Train trên bert_base_uncased\n","\n","- Sử dụng mô hình có sẵn trên tensorflow\n","- Mô hình này sẽ sử lý sẵn nên không cần sẵn lý dữ liệu trước đó.\n","- Tạo 1 lớp dropout, lớp ẩn(Dense) chứa hàm kích hoạt, lớp cuối cùng dùng hàm softmax để dự đoán và học.\n","- Có thể tăng hoặc giảm số lượng lớp Dense. Tùy thuộc vào mô hình. Càng nhiều lớp thì mô hình càng nặng. Tương tự như lớp, thì số node trong lớp có thể tăng hoặc giảm.\n"],"metadata":{"id":"ssFjtIkxNvwD"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"0zC0pqJH0BTf"},"outputs":[],"source":["bert_preprocess = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n","bert_encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5xU-Y5QU0ry8"},"outputs":[],"source":["# Bert layers\n","text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n","preprocessed_text = bert_preprocess(text_input)\n","outputs = bert_encoder(preprocessed_text)\n","\n","# Neural network layers\n","l = tf.keras.layers.Dropout(0.1, name=\"dropout\")(outputs['pooled_output'])\n","l = tf.keras.layers.Dense(32, activation='relu')(l)\n","l = tf.keras.layers.Dense(16, activation='relu')(l)\n","l = tf.keras.layers.Dense(3, activation='softmax', name=\"output\")(l)\n","\n","# Use inputs and outputs to construct a final model\n","model = tf.keras.Model(inputs=[text_input], outputs = [l])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":387,"status":"ok","timestamp":1695095288222,"user":{"displayName":"9370 _ Phạm Thiện Tài","userId":"17496006235026682420"},"user_tz":-420},"id":"eG57NJyr1saw","outputId":"d7b3fb8d-6ac3-4d55-d4f4-8af14f502be6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                Output Shape                 Param #   Connected to                  \n","==================================================================================================\n"," text (InputLayer)           [(None,)]                    0         []                            \n","                                                                                                  \n"," keras_layer_9 (KerasLayer)  {'input_mask': (None, 128)   0         ['text[0][0]']                \n","                             , 'input_word_ids': (None,                                           \n","                              128),                                                               \n","                              'input_type_ids': (None,                                            \n","                             128)}                                                                \n","                                                                                                  \n"," keras_layer_10 (KerasLayer  {'encoder_outputs': [(None   1094822   ['keras_layer_9[0][0]',       \n"," )                           , 128, 768),                 41         'keras_layer_9[0][1]',       \n","                              (None, 128, 768),                      'keras_layer_9[0][2]']       \n","                              (None, 128, 768),                                                   \n","                              (None, 128, 768),                                                   \n","                              (None, 128, 768),                                                   \n","                              (None, 128, 768),                                                   \n","                              (None, 128, 768),                                                   \n","                              (None, 128, 768),                                                   \n","                              (None, 128, 768),                                                   \n","                              (None, 128, 768),                                                   \n","                              (None, 128, 768),                                                   \n","                              (None, 128, 768)],                                                  \n","                              'default': (None, 768),                                             \n","                              'sequence_output': (None,                                           \n","                              128, 768),                                                          \n","                              'pooled_output': (None, 7                                           \n","                             68)}                                                                 \n","                                                                                                  \n"," dropout (Dropout)           (None, 768)                  0         ['keras_layer_10[0][13]']     \n","                                                                                                  \n"," dense_40 (Dense)            (None, 32)                   24608     ['dropout[0][0]']             \n","                                                                                                  \n"," dense_41 (Dense)            (None, 16)                   528       ['dense_40[0][0]']            \n","                                                                                                  \n"," output (Dense)              (None, 3)                    51        ['dense_41[0][0]']            \n","                                                                                                  \n","==================================================================================================\n","Total params: 109507428 (417.74 MB)\n","Trainable params: 25187 (98.39 KB)\n","Non-trainable params: 109482241 (417.64 MB)\n","__________________________________________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"07KrUk661s50"},"outputs":[],"source":["model.compile(loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False),optimizer=tf.keras.optimizers.Adam(),metrics=['accuracy'])\n","# METRICS = [\n","#       tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n","#       tf.keras.metrics.Precision(name='precision'),\n","#       tf.keras.metrics.Recall(name='recall')\n","# ]\n","\n","# model.compile(optimizer='adam',\n","#               loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n","#               metrics=METRICS)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"izWkK-ntiZgN"},"outputs":[],"source":["X = df['sentence'].values\n","y = df['sentiment'].values"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2282259,"status":"ok","timestamp":1695097570477,"user":{"displayName":"9370 _ Phạm Thiện Tài","userId":"17496006235026682420"},"user_tz":-420},"id":"UI8fljJm1wvP","outputId":"c00d97b6-6c53-4514-e11b-c19af9baf076"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","1/1 - 33s - loss: 1.3382 - accuracy: 0.1724 - val_loss: 1.3208 - val_accuracy: 0.1538 - 33s/epoch - 33s/step\n","Epoch 2/100\n","1/1 - 25s - loss: 1.1255 - accuracy: 0.4483 - val_loss: 1.3843 - val_accuracy: 0.1538 - 25s/epoch - 25s/step\n","Epoch 3/100\n","1/1 - 20s - loss: 1.0761 - accuracy: 0.4483 - val_loss: 1.3655 - val_accuracy: 0.1538 - 20s/epoch - 20s/step\n","Epoch 4/100\n","1/1 - 21s - loss: 1.0632 - accuracy: 0.4828 - val_loss: 1.2462 - val_accuracy: 0.1538 - 21s/epoch - 21s/step\n","Epoch 5/100\n","1/1 - 24s - loss: 1.0186 - accuracy: 0.4828 - val_loss: 1.1450 - val_accuracy: 0.2308 - 24s/epoch - 24s/step\n","Epoch 6/100\n","1/1 - 24s - loss: 1.0299 - accuracy: 0.4828 - val_loss: 1.1001 - val_accuracy: 0.5385 - 24s/epoch - 24s/step\n","Epoch 7/100\n","1/1 - 25s - loss: 0.9807 - accuracy: 0.5172 - val_loss: 1.0836 - val_accuracy: 0.5385 - 25s/epoch - 25s/step\n","Epoch 8/100\n","1/1 - 19s - loss: 1.0535 - accuracy: 0.4483 - val_loss: 1.1358 - val_accuracy: 0.4615 - 19s/epoch - 19s/step\n","Epoch 9/100\n","1/1 - 25s - loss: 0.9598 - accuracy: 0.5862 - val_loss: 1.2148 - val_accuracy: 0.1538 - 25s/epoch - 25s/step\n","Epoch 10/100\n","1/1 - 23s - loss: 0.9473 - accuracy: 0.5172 - val_loss: 1.2650 - val_accuracy: 0.1538 - 23s/epoch - 23s/step\n","Epoch 11/100\n","1/1 - 25s - loss: 1.0336 - accuracy: 0.4138 - val_loss: 1.2569 - val_accuracy: 0.1538 - 25s/epoch - 25s/step\n","Epoch 12/100\n","1/1 - 25s - loss: 1.0092 - accuracy: 0.5517 - val_loss: 1.1730 - val_accuracy: 0.4615 - 25s/epoch - 25s/step\n","Epoch 13/100\n","1/1 - 21s - loss: 1.0039 - accuracy: 0.4828 - val_loss: 1.0929 - val_accuracy: 0.5385 - 21s/epoch - 21s/step\n","Epoch 14/100\n","1/1 - 23s - loss: 1.0494 - accuracy: 0.4138 - val_loss: 1.0680 - val_accuracy: 0.5385 - 23s/epoch - 23s/step\n","Epoch 15/100\n","1/1 - 19s - loss: 0.9949 - accuracy: 0.5517 - val_loss: 1.0815 - val_accuracy: 0.5385 - 19s/epoch - 19s/step\n","Epoch 16/100\n","1/1 - 25s - loss: 0.9943 - accuracy: 0.5862 - val_loss: 1.1236 - val_accuracy: 0.5385 - 25s/epoch - 25s/step\n","Epoch 17/100\n","1/1 - 20s - loss: 1.0027 - accuracy: 0.5517 - val_loss: 1.1780 - val_accuracy: 0.4615 - 20s/epoch - 20s/step\n","Epoch 18/100\n","1/1 - 20s - loss: 0.9859 - accuracy: 0.5172 - val_loss: 1.2068 - val_accuracy: 0.2308 - 20s/epoch - 20s/step\n","Epoch 19/100\n","1/1 - 25s - loss: 0.9850 - accuracy: 0.5517 - val_loss: 1.2129 - val_accuracy: 0.2308 - 25s/epoch - 25s/step\n","Epoch 20/100\n","1/1 - 25s - loss: 0.9737 - accuracy: 0.4483 - val_loss: 1.1920 - val_accuracy: 0.2308 - 25s/epoch - 25s/step\n","Epoch 21/100\n","1/1 - 22s - loss: 0.9965 - accuracy: 0.4483 - val_loss: 1.1493 - val_accuracy: 0.4615 - 22s/epoch - 22s/step\n","Epoch 22/100\n","1/1 - 23s - loss: 0.9804 - accuracy: 0.6207 - val_loss: 1.1221 - val_accuracy: 0.5385 - 23s/epoch - 23s/step\n","Epoch 23/100\n","1/1 - 25s - loss: 0.9836 - accuracy: 0.5517 - val_loss: 1.1060 - val_accuracy: 0.5385 - 25s/epoch - 25s/step\n","Epoch 24/100\n","1/1 - 24s - loss: 0.9690 - accuracy: 0.5517 - val_loss: 1.1013 - val_accuracy: 0.5385 - 24s/epoch - 24s/step\n","Epoch 25/100\n","1/1 - 25s - loss: 0.9861 - accuracy: 0.4483 - val_loss: 1.1120 - val_accuracy: 0.5385 - 25s/epoch - 25s/step\n","Epoch 26/100\n","1/1 - 20s - loss: 0.9640 - accuracy: 0.5172 - val_loss: 1.1307 - val_accuracy: 0.5385 - 20s/epoch - 20s/step\n","Epoch 27/100\n","1/1 - 19s - loss: 0.9833 - accuracy: 0.4483 - val_loss: 1.1415 - val_accuracy: 0.5385 - 19s/epoch - 19s/step\n","Epoch 28/100\n","1/1 - 24s - loss: 0.9723 - accuracy: 0.5517 - val_loss: 1.1392 - val_accuracy: 0.5385 - 24s/epoch - 24s/step\n","Epoch 29/100\n","1/1 - 20s - loss: 0.9631 - accuracy: 0.6207 - val_loss: 1.1180 - val_accuracy: 0.5385 - 20s/epoch - 20s/step\n","Epoch 30/100\n","1/1 - 20s - loss: 0.9714 - accuracy: 0.4483 - val_loss: 1.0965 - val_accuracy: 0.5385 - 20s/epoch - 20s/step\n","Epoch 31/100\n","1/1 - 25s - loss: 0.9675 - accuracy: 0.5172 - val_loss: 1.0824 - val_accuracy: 0.5385 - 25s/epoch - 25s/step\n","Epoch 32/100\n","1/1 - 25s - loss: 0.9473 - accuracy: 0.5172 - val_loss: 1.0674 - val_accuracy: 0.5385 - 25s/epoch - 25s/step\n","Epoch 33/100\n","1/1 - 24s - loss: 0.9724 - accuracy: 0.5172 - val_loss: 1.0635 - val_accuracy: 0.5385 - 24s/epoch - 24s/step\n","Epoch 34/100\n","1/1 - 25s - loss: 0.9579 - accuracy: 0.5862 - val_loss: 1.0705 - val_accuracy: 0.5385 - 25s/epoch - 25s/step\n","Epoch 35/100\n","1/1 - 24s - loss: 0.9514 - accuracy: 0.4828 - val_loss: 1.0860 - val_accuracy: 0.5385 - 24s/epoch - 24s/step\n","Epoch 36/100\n","1/1 - 20s - loss: 0.9482 - accuracy: 0.5172 - val_loss: 1.1140 - val_accuracy: 0.5385 - 20s/epoch - 20s/step\n","Epoch 37/100\n","1/1 - 25s - loss: 0.9535 - accuracy: 0.5862 - val_loss: 1.1333 - val_accuracy: 0.5385 - 25s/epoch - 25s/step\n","Epoch 38/100\n","1/1 - 24s - loss: 0.9848 - accuracy: 0.4828 - val_loss: 1.1361 - val_accuracy: 0.5385 - 24s/epoch - 24s/step\n","Epoch 39/100\n","1/1 - 25s - loss: 0.9401 - accuracy: 0.5517 - val_loss: 1.1094 - val_accuracy: 0.5385 - 25s/epoch - 25s/step\n","Epoch 40/100\n","1/1 - 20s - loss: 0.9942 - accuracy: 0.4828 - val_loss: 1.0733 - val_accuracy: 0.5385 - 20s/epoch - 20s/step\n","Epoch 41/100\n","1/1 - 19s - loss: 0.9241 - accuracy: 0.6552 - val_loss: 1.0582 - val_accuracy: 0.5385 - 19s/epoch - 19s/step\n","Epoch 42/100\n","1/1 - 25s - loss: 0.9141 - accuracy: 0.5862 - val_loss: 1.0507 - val_accuracy: 0.5385 - 25s/epoch - 25s/step\n","Epoch 43/100\n","1/1 - 20s - loss: 0.9349 - accuracy: 0.6207 - val_loss: 1.0578 - val_accuracy: 0.5385 - 20s/epoch - 20s/step\n","Epoch 44/100\n","1/1 - 24s - loss: 0.9309 - accuracy: 0.5862 - val_loss: 1.0786 - val_accuracy: 0.5385 - 24s/epoch - 24s/step\n","Epoch 45/100\n","1/1 - 23s - loss: 0.9471 - accuracy: 0.5172 - val_loss: 1.0954 - val_accuracy: 0.5385 - 23s/epoch - 23s/step\n","Epoch 46/100\n","1/1 - 27s - loss: 0.9012 - accuracy: 0.5862 - val_loss: 1.1114 - val_accuracy: 0.5385 - 27s/epoch - 27s/step\n","Epoch 47/100\n","1/1 - 25s - loss: 0.9592 - accuracy: 0.5862 - val_loss: 1.1128 - val_accuracy: 0.5385 - 25s/epoch - 25s/step\n","Epoch 48/100\n","1/1 - 24s - loss: 0.9341 - accuracy: 0.5172 - val_loss: 1.0909 - val_accuracy: 0.5385 - 24s/epoch - 24s/step\n","Epoch 49/100\n","1/1 - 25s - loss: 0.9438 - accuracy: 0.5172 - val_loss: 1.0755 - val_accuracy: 0.5385 - 25s/epoch - 25s/step\n","Epoch 50/100\n","1/1 - 24s - loss: 0.9377 - accuracy: 0.5862 - val_loss: 1.0670 - val_accuracy: 0.5385 - 24s/epoch - 24s/step\n","Epoch 51/100\n","1/1 - 19s - loss: 0.9085 - accuracy: 0.5862 - val_loss: 1.0697 - val_accuracy: 0.5385 - 19s/epoch - 19s/step\n","Epoch 52/100\n","1/1 - 25s - loss: 0.9162 - accuracy: 0.6207 - val_loss: 1.0858 - val_accuracy: 0.5385 - 25s/epoch - 25s/step\n","Epoch 53/100\n","1/1 - 24s - loss: 0.9373 - accuracy: 0.5862 - val_loss: 1.1095 - val_accuracy: 0.5385 - 24s/epoch - 24s/step\n","Epoch 54/100\n","1/1 - 25s - loss: 0.9350 - accuracy: 0.5862 - val_loss: 1.1275 - val_accuracy: 0.5385 - 25s/epoch - 25s/step\n","Epoch 55/100\n","1/1 - 20s - loss: 0.9034 - accuracy: 0.5517 - val_loss: 1.1120 - val_accuracy: 0.5385 - 20s/epoch - 20s/step\n","Epoch 56/100\n","1/1 - 20s - loss: 0.8942 - accuracy: 0.6207 - val_loss: 1.0873 - val_accuracy: 0.5385 - 20s/epoch - 20s/step\n","Epoch 57/100\n","1/1 - 25s - loss: 0.9191 - accuracy: 0.6552 - val_loss: 1.0631 - val_accuracy: 0.5385 - 25s/epoch - 25s/step\n","Epoch 58/100\n","1/1 - 25s - loss: 0.9944 - accuracy: 0.5172 - val_loss: 1.0561 - val_accuracy: 0.5385 - 25s/epoch - 25s/step\n","Epoch 59/100\n","1/1 - 25s - loss: 0.9431 - accuracy: 0.5862 - val_loss: 1.0743 - val_accuracy: 0.5385 - 25s/epoch - 25s/step\n","Epoch 60/100\n","1/1 - 25s - loss: 0.9411 - accuracy: 0.4828 - val_loss: 1.1054 - val_accuracy: 0.5385 - 25s/epoch - 25s/step\n","Epoch 61/100\n","1/1 - 24s - loss: 0.9653 - accuracy: 0.5172 - val_loss: 1.1485 - val_accuracy: 0.5385 - 24s/epoch - 24s/step\n","Epoch 62/100\n","1/1 - 20s - loss: 0.9384 - accuracy: 0.5172 - val_loss: 1.1807 - val_accuracy: 0.4615 - 20s/epoch - 20s/step\n","Epoch 63/100\n","1/1 - 20s - loss: 0.9488 - accuracy: 0.5172 - val_loss: 1.1516 - val_accuracy: 0.5385 - 20s/epoch - 20s/step\n","Epoch 64/100\n","1/1 - 22s - loss: 0.8922 - accuracy: 0.6207 - val_loss: 1.1049 - val_accuracy: 0.5385 - 22s/epoch - 22s/step\n","Epoch 65/100\n","1/1 - 23s - loss: 0.8797 - accuracy: 0.6207 - val_loss: 1.0699 - val_accuracy: 0.5385 - 23s/epoch - 23s/step\n","Epoch 66/100\n","1/1 - 20s - loss: 0.8676 - accuracy: 0.6207 - val_loss: 1.0636 - val_accuracy: 0.5385 - 20s/epoch - 20s/step\n","Epoch 67/100\n","1/1 - 25s - loss: 0.9040 - accuracy: 0.5172 - val_loss: 1.0674 - val_accuracy: 0.5385 - 25s/epoch - 25s/step\n","Epoch 68/100\n","1/1 - 20s - loss: 0.9026 - accuracy: 0.5862 - val_loss: 1.0791 - val_accuracy: 0.5385 - 20s/epoch - 20s/step\n","Epoch 69/100\n","1/1 - 25s - loss: 0.9175 - accuracy: 0.5517 - val_loss: 1.0962 - val_accuracy: 0.5385 - 25s/epoch - 25s/step\n","Epoch 70/100\n","1/1 - 23s - loss: 0.9170 - accuracy: 0.5172 - val_loss: 1.1112 - val_accuracy: 0.5385 - 23s/epoch - 23s/step\n","Epoch 71/100\n","1/1 - 25s - loss: 0.9226 - accuracy: 0.6207 - val_loss: 1.1281 - val_accuracy: 0.5385 - 25s/epoch - 25s/step\n","Epoch 72/100\n","1/1 - 25s - loss: 0.8975 - accuracy: 0.5862 - val_loss: 1.1524 - val_accuracy: 0.5385 - 25s/epoch - 25s/step\n","Epoch 73/100\n","1/1 - 25s - loss: 0.8826 - accuracy: 0.5862 - val_loss: 1.1498 - val_accuracy: 0.5385 - 25s/epoch - 25s/step\n","Epoch 74/100\n","1/1 - 20s - loss: 0.8362 - accuracy: 0.6897 - val_loss: 1.1193 - val_accuracy: 0.5385 - 20s/epoch - 20s/step\n","Epoch 75/100\n","1/1 - 19s - loss: 0.8663 - accuracy: 0.6897 - val_loss: 1.0832 - val_accuracy: 0.5385 - 19s/epoch - 19s/step\n","Epoch 76/100\n","1/1 - 24s - loss: 0.9108 - accuracy: 0.5172 - val_loss: 1.0500 - val_accuracy: 0.5385 - 24s/epoch - 24s/step\n","Epoch 77/100\n","1/1 - 25s - loss: 0.8632 - accuracy: 0.6552 - val_loss: 1.0498 - val_accuracy: 0.5385 - 25s/epoch - 25s/step\n","Epoch 78/100\n","1/1 - 25s - loss: 0.8448 - accuracy: 0.5862 - val_loss: 1.0723 - val_accuracy: 0.5385 - 25s/epoch - 25s/step\n","Epoch 79/100\n","1/1 - 20s - loss: 0.9036 - accuracy: 0.5862 - val_loss: 1.0937 - val_accuracy: 0.5385 - 20s/epoch - 20s/step\n","Epoch 80/100\n","1/1 - 20s - loss: 0.8699 - accuracy: 0.5862 - val_loss: 1.1060 - val_accuracy: 0.5385 - 20s/epoch - 20s/step\n","Epoch 81/100\n","1/1 - 25s - loss: 0.8463 - accuracy: 0.6207 - val_loss: 1.0951 - val_accuracy: 0.5385 - 25s/epoch - 25s/step\n","Epoch 82/100\n","1/1 - 20s - loss: 0.8284 - accuracy: 0.6207 - val_loss: 1.0624 - val_accuracy: 0.5385 - 20s/epoch - 20s/step\n","Epoch 83/100\n","1/1 - 20s - loss: 0.8774 - accuracy: 0.5517 - val_loss: 1.0395 - val_accuracy: 0.5385 - 20s/epoch - 20s/step\n","Epoch 84/100\n","1/1 - 25s - loss: 0.8154 - accuracy: 0.6897 - val_loss: 1.0260 - val_accuracy: 0.5385 - 25s/epoch - 25s/step\n","Epoch 85/100\n","1/1 - 25s - loss: 0.8980 - accuracy: 0.6552 - val_loss: 1.0557 - val_accuracy: 0.5385 - 25s/epoch - 25s/step\n","Epoch 86/100\n","1/1 - 25s - loss: 0.8591 - accuracy: 0.6207 - val_loss: 1.1155 - val_accuracy: 0.5385 - 25s/epoch - 25s/step\n","Epoch 87/100\n","1/1 - 20s - loss: 0.8437 - accuracy: 0.6897 - val_loss: 1.1500 - val_accuracy: 0.5385 - 20s/epoch - 20s/step\n","Epoch 88/100\n","1/1 - 20s - loss: 0.8244 - accuracy: 0.6207 - val_loss: 1.1172 - val_accuracy: 0.5385 - 20s/epoch - 20s/step\n","Epoch 89/100\n","1/1 - 25s - loss: 0.8774 - accuracy: 0.5862 - val_loss: 1.0618 - val_accuracy: 0.5385 - 25s/epoch - 25s/step\n","Epoch 90/100\n","1/1 - 20s - loss: 0.8272 - accuracy: 0.6207 - val_loss: 1.0168 - val_accuracy: 0.5385 - 20s/epoch - 20s/step\n","Epoch 91/100\n","1/1 - 20s - loss: 0.8842 - accuracy: 0.6207 - val_loss: 1.0105 - val_accuracy: 0.5385 - 20s/epoch - 20s/step\n","Epoch 92/100\n","1/1 - 25s - loss: 0.8272 - accuracy: 0.6207 - val_loss: 1.0391 - val_accuracy: 0.5385 - 25s/epoch - 25s/step\n","Epoch 93/100\n","1/1 - 25s - loss: 0.8440 - accuracy: 0.5862 - val_loss: 1.0873 - val_accuracy: 0.5385 - 25s/epoch - 25s/step\n","Epoch 94/100\n","1/1 - 24s - loss: 0.8006 - accuracy: 0.6552 - val_loss: 1.1254 - val_accuracy: 0.5385 - 24s/epoch - 24s/step\n","Epoch 95/100\n","1/1 - 19s - loss: 0.8312 - accuracy: 0.6552 - val_loss: 1.1370 - val_accuracy: 0.5385 - 19s/epoch - 19s/step\n","Epoch 96/100\n","1/1 - 20s - loss: 0.8520 - accuracy: 0.5862 - val_loss: 1.1009 - val_accuracy: 0.5385 - 20s/epoch - 20s/step\n","Epoch 97/100\n","1/1 - 25s - loss: 0.7950 - accuracy: 0.7241 - val_loss: 1.0535 - val_accuracy: 0.5385 - 25s/epoch - 25s/step\n","Epoch 98/100\n","1/1 - 20s - loss: 0.8510 - accuracy: 0.6552 - val_loss: 1.0357 - val_accuracy: 0.5385 - 20s/epoch - 20s/step\n","Epoch 99/100\n","1/1 - 25s - loss: 0.8426 - accuracy: 0.6897 - val_loss: 1.0567 - val_accuracy: 0.5385 - 25s/epoch - 25s/step\n","Epoch 100/100\n","1/1 - 23s - loss: 0.8313 - accuracy: 0.6552 - val_loss: 1.0859 - val_accuracy: 0.5385 - 23s/epoch - 23s/step\n"]}],"source":["history = model.fit(X, y, epochs = 100, validation_split=0.3, verbose=2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HQjiuOZN6JxF"},"outputs":[],"source":["#######################################################################################################################################"]},{"cell_type":"markdown","source":["# Phần này bỏ"],"metadata":{"id":"nkgc5hW7Vm7c"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"EwwM971S8Bqw"},"outputs":[],"source":["# albert_module = hub.load(\"https://tfhub.dev/google/albert_base/3\")\n","# #albert_module.signatures['default'](['<OOV>', 'và'])\n","# albert_inputs = dict(input_ids=word_index)\n","\n","# albert_outputs = albert_module(albert_inputs, signature=\"<OOV>\", as_dict=True)\n","\n","# pooled_output = albert_outputs[\"pooled_output\"]\n","# sequence_output = albert_outputs[\"sequence_output\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xx6ZvAGnq8Qv"},"outputs":[],"source":["hub_layer = hub.KerasLayer(\"https://tfhub.dev/google/albert_base/3\",input_shape=[], dtype=tf.string)\n","\n","model = keras.Sequential()\n","model.add(hub_layer)\n","model.add(keras.layers.Dense(16, activation='relu'))\n","model.add(keras.layers.Dense(3, activation='sigmoid'))\n","\n","model.summary()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NZ7h6qm-qzy1"},"outputs":[],"source":["##################################################################################################################################################"]},{"cell_type":"markdown","source":["# Train trên NNLM model\n","- Mô hình không có xử lý sẵn dữ liệu nên sẽ phải xử lý dữ liệu trước đó, sau đó mới đưa vào mô hình để train.\n","- Tạo 3 lớp Dense và 1 lớp có hàm kích hoạt \"sigmoid\" để dự máy có thể học và dự đoán.\n","- Có thể tăng hoặc giảm số lượng lớp Dense. Tùy thuộc vào mô hình. Càng nhiều lớp thì mô hình càng nặng. Tương tự như lớp, thì số node trong lớp có thể tăng hoặc giảm."],"metadata":{"id":"XLxylBPgUe12"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"vOYGZeX9BIgx"},"outputs":[],"source":["hub_layer = hub.KerasLayer(\"https://tfhub.dev/google/nnlm-en-dim50/2\",input_shape=[], dtype=tf.string)\n","\n","model = keras.Sequential()\n","model.add(hub_layer)\n","#model.add(keras.layers.Dense(64, activation='relu'))\n","#model.add(keras.layers.Dense(128, activation='relu'))\n","model.add(keras.layers.Dense(64, activation='relu'))\n","model.add(keras.layers.Dense(32, activation='relu'))\n","model.add(keras.layers.Dense(16, activation='relu'))\n","model.add(keras.layers.Dense(3, activation='sigmoid'))\n","\n","model.summary()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lRUO8EdXpXPC"},"outputs":[],"source":["model.compile(loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False),optimizer=tf.keras.optimizers.Adam(),metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MaLXXKyOpXv4"},"outputs":[],"source":["X = df['sentence'].values\n","y = df['sentiment'].values"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14667,"status":"ok","timestamp":1695094840791,"user":{"displayName":"9370 _ Phạm Thiện Tài","userId":"17496006235026682420"},"user_tz":-420},"id":"d3CfRIKepbGv","outputId":"8d62fd2e-da89-4bcc-98e2-2de806308d9f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","1/1 - 4s - loss: 1.0993 - accuracy: 0.4138 - val_loss: 1.1152 - val_accuracy: 0.1538 - 4s/epoch - 4s/step\n","Epoch 2/100\n","1/1 - 0s - loss: 1.0903 - accuracy: 0.4138 - val_loss: 1.1154 - val_accuracy: 0.1538 - 117ms/epoch - 117ms/step\n","Epoch 3/100\n","1/1 - 0s - loss: 1.0825 - accuracy: 0.4483 - val_loss: 1.1145 - val_accuracy: 0.1538 - 85ms/epoch - 85ms/step\n","Epoch 4/100\n","1/1 - 0s - loss: 1.0756 - accuracy: 0.4483 - val_loss: 1.1141 - val_accuracy: 0.1538 - 81ms/epoch - 81ms/step\n","Epoch 5/100\n","1/1 - 0s - loss: 1.0682 - accuracy: 0.4828 - val_loss: 1.1138 - val_accuracy: 0.1538 - 97ms/epoch - 97ms/step\n","Epoch 6/100\n","1/1 - 0s - loss: 1.0602 - accuracy: 0.4828 - val_loss: 1.1137 - val_accuracy: 0.1538 - 95ms/epoch - 95ms/step\n","Epoch 7/100\n","1/1 - 0s - loss: 1.0512 - accuracy: 0.4828 - val_loss: 1.1149 - val_accuracy: 0.1538 - 76ms/epoch - 76ms/step\n","Epoch 8/100\n","1/1 - 0s - loss: 1.0416 - accuracy: 0.4828 - val_loss: 1.1164 - val_accuracy: 0.1538 - 124ms/epoch - 124ms/step\n","Epoch 9/100\n","1/1 - 0s - loss: 1.0315 - accuracy: 0.4828 - val_loss: 1.1177 - val_accuracy: 0.1538 - 90ms/epoch - 90ms/step\n","Epoch 10/100\n","1/1 - 0s - loss: 1.0211 - accuracy: 0.4828 - val_loss: 1.1181 - val_accuracy: 0.1538 - 99ms/epoch - 99ms/step\n","Epoch 11/100\n","1/1 - 0s - loss: 1.0106 - accuracy: 0.4828 - val_loss: 1.1181 - val_accuracy: 0.1538 - 108ms/epoch - 108ms/step\n","Epoch 12/100\n","1/1 - 0s - loss: 1.0002 - accuracy: 0.4828 - val_loss: 1.1181 - val_accuracy: 0.1538 - 76ms/epoch - 76ms/step\n","Epoch 13/100\n","1/1 - 0s - loss: 0.9900 - accuracy: 0.4828 - val_loss: 1.1183 - val_accuracy: 0.1538 - 93ms/epoch - 93ms/step\n","Epoch 14/100\n","1/1 - 0s - loss: 0.9799 - accuracy: 0.4828 - val_loss: 1.1192 - val_accuracy: 0.1538 - 88ms/epoch - 88ms/step\n","Epoch 15/100\n","1/1 - 0s - loss: 0.9705 - accuracy: 0.4828 - val_loss: 1.1206 - val_accuracy: 0.1538 - 107ms/epoch - 107ms/step\n","Epoch 16/100\n","1/1 - 0s - loss: 0.9617 - accuracy: 0.4828 - val_loss: 1.1219 - val_accuracy: 0.1538 - 82ms/epoch - 82ms/step\n","Epoch 17/100\n","1/1 - 0s - loss: 0.9529 - accuracy: 0.4828 - val_loss: 1.1230 - val_accuracy: 0.1538 - 99ms/epoch - 99ms/step\n","Epoch 18/100\n","1/1 - 0s - loss: 0.9443 - accuracy: 0.4828 - val_loss: 1.1244 - val_accuracy: 0.1538 - 91ms/epoch - 91ms/step\n","Epoch 19/100\n","1/1 - 0s - loss: 0.9360 - accuracy: 0.4828 - val_loss: 1.1261 - val_accuracy: 0.1538 - 82ms/epoch - 82ms/step\n","Epoch 20/100\n","1/1 - 0s - loss: 0.9277 - accuracy: 0.4828 - val_loss: 1.1281 - val_accuracy: 0.1538 - 103ms/epoch - 103ms/step\n","Epoch 21/100\n","1/1 - 0s - loss: 0.9195 - accuracy: 0.4828 - val_loss: 1.1299 - val_accuracy: 0.1538 - 98ms/epoch - 98ms/step\n","Epoch 22/100\n","1/1 - 0s - loss: 0.9111 - accuracy: 0.4828 - val_loss: 1.1318 - val_accuracy: 0.1538 - 139ms/epoch - 139ms/step\n","Epoch 23/100\n","1/1 - 0s - loss: 0.9026 - accuracy: 0.4828 - val_loss: 1.1334 - val_accuracy: 0.1538 - 109ms/epoch - 109ms/step\n","Epoch 24/100\n","1/1 - 0s - loss: 0.8937 - accuracy: 0.4828 - val_loss: 1.1351 - val_accuracy: 0.1538 - 87ms/epoch - 87ms/step\n","Epoch 25/100\n","1/1 - 0s - loss: 0.8846 - accuracy: 0.4828 - val_loss: 1.1354 - val_accuracy: 0.1538 - 77ms/epoch - 77ms/step\n","Epoch 26/100\n","1/1 - 0s - loss: 0.8751 - accuracy: 0.4828 - val_loss: 1.1337 - val_accuracy: 0.1538 - 69ms/epoch - 69ms/step\n","Epoch 27/100\n","1/1 - 0s - loss: 0.8654 - accuracy: 0.4828 - val_loss: 1.1311 - val_accuracy: 0.1538 - 68ms/epoch - 68ms/step\n","Epoch 28/100\n","1/1 - 0s - loss: 0.8554 - accuracy: 0.5172 - val_loss: 1.1275 - val_accuracy: 0.1538 - 65ms/epoch - 65ms/step\n","Epoch 29/100\n","1/1 - 0s - loss: 0.8451 - accuracy: 0.5172 - val_loss: 1.1228 - val_accuracy: 0.1538 - 73ms/epoch - 73ms/step\n","Epoch 30/100\n","1/1 - 0s - loss: 0.8346 - accuracy: 0.5172 - val_loss: 1.1178 - val_accuracy: 0.1538 - 72ms/epoch - 72ms/step\n","Epoch 31/100\n","1/1 - 0s - loss: 0.8241 - accuracy: 0.5517 - val_loss: 1.1125 - val_accuracy: 0.1538 - 77ms/epoch - 77ms/step\n","Epoch 32/100\n","1/1 - 0s - loss: 0.8138 - accuracy: 0.5862 - val_loss: 1.1071 - val_accuracy: 0.1538 - 64ms/epoch - 64ms/step\n","Epoch 33/100\n","1/1 - 0s - loss: 0.8033 - accuracy: 0.5862 - val_loss: 1.1021 - val_accuracy: 0.1538 - 65ms/epoch - 65ms/step\n","Epoch 34/100\n","1/1 - 0s - loss: 0.7927 - accuracy: 0.5862 - val_loss: 1.0976 - val_accuracy: 0.1538 - 69ms/epoch - 69ms/step\n","Epoch 35/100\n","1/1 - 0s - loss: 0.7817 - accuracy: 0.6207 - val_loss: 1.0935 - val_accuracy: 0.1538 - 55ms/epoch - 55ms/step\n","Epoch 36/100\n","1/1 - 0s - loss: 0.7705 - accuracy: 0.6552 - val_loss: 1.0900 - val_accuracy: 0.1538 - 77ms/epoch - 77ms/step\n","Epoch 37/100\n","1/1 - 0s - loss: 0.7588 - accuracy: 0.6552 - val_loss: 1.0871 - val_accuracy: 0.2308 - 75ms/epoch - 75ms/step\n","Epoch 38/100\n","1/1 - 0s - loss: 0.7469 - accuracy: 0.7241 - val_loss: 1.0838 - val_accuracy: 0.2308 - 60ms/epoch - 60ms/step\n","Epoch 39/100\n","1/1 - 0s - loss: 0.7350 - accuracy: 0.7241 - val_loss: 1.0808 - val_accuracy: 0.2308 - 113ms/epoch - 113ms/step\n","Epoch 40/100\n","1/1 - 0s - loss: 0.7232 - accuracy: 0.7241 - val_loss: 1.0773 - val_accuracy: 0.2308 - 182ms/epoch - 182ms/step\n","Epoch 41/100\n","1/1 - 0s - loss: 0.7113 - accuracy: 0.7586 - val_loss: 1.0730 - val_accuracy: 0.2308 - 194ms/epoch - 194ms/step\n","Epoch 42/100\n","1/1 - 0s - loss: 0.6994 - accuracy: 0.7586 - val_loss: 1.0677 - val_accuracy: 0.2308 - 139ms/epoch - 139ms/step\n","Epoch 43/100\n","1/1 - 0s - loss: 0.6875 - accuracy: 0.7931 - val_loss: 1.0630 - val_accuracy: 0.3077 - 115ms/epoch - 115ms/step\n","Epoch 44/100\n","1/1 - 0s - loss: 0.6754 - accuracy: 0.7931 - val_loss: 1.0584 - val_accuracy: 0.3077 - 182ms/epoch - 182ms/step\n","Epoch 45/100\n","1/1 - 0s - loss: 0.6628 - accuracy: 0.7931 - val_loss: 1.0546 - val_accuracy: 0.4615 - 134ms/epoch - 134ms/step\n","Epoch 46/100\n","1/1 - 0s - loss: 0.6502 - accuracy: 0.7931 - val_loss: 1.0535 - val_accuracy: 0.5385 - 67ms/epoch - 67ms/step\n","Epoch 47/100\n","1/1 - 0s - loss: 0.6373 - accuracy: 0.7931 - val_loss: 1.0541 - val_accuracy: 0.5385 - 33ms/epoch - 33ms/step\n","Epoch 48/100\n","1/1 - 0s - loss: 0.6239 - accuracy: 0.7931 - val_loss: 1.0521 - val_accuracy: 0.5385 - 33ms/epoch - 33ms/step\n","Epoch 49/100\n","1/1 - 0s - loss: 0.6108 - accuracy: 0.8276 - val_loss: 1.0446 - val_accuracy: 0.5385 - 35ms/epoch - 35ms/step\n","Epoch 50/100\n","1/1 - 0s - loss: 0.5971 - accuracy: 0.8276 - val_loss: 1.0326 - val_accuracy: 0.5385 - 36ms/epoch - 36ms/step\n","Epoch 51/100\n","1/1 - 0s - loss: 0.5835 - accuracy: 0.8621 - val_loss: 1.0243 - val_accuracy: 0.6154 - 37ms/epoch - 37ms/step\n","Epoch 52/100\n","1/1 - 0s - loss: 0.5696 - accuracy: 0.8966 - val_loss: 1.0206 - val_accuracy: 0.6154 - 37ms/epoch - 37ms/step\n","Epoch 53/100\n","1/1 - 0s - loss: 0.5553 - accuracy: 0.8966 - val_loss: 1.0178 - val_accuracy: 0.6154 - 40ms/epoch - 40ms/step\n","Epoch 54/100\n","1/1 - 0s - loss: 0.5412 - accuracy: 0.8966 - val_loss: 1.0121 - val_accuracy: 0.6154 - 52ms/epoch - 52ms/step\n","Epoch 55/100\n","1/1 - 0s - loss: 0.5271 - accuracy: 0.8966 - val_loss: 1.0002 - val_accuracy: 0.6154 - 35ms/epoch - 35ms/step\n","Epoch 56/100\n","1/1 - 0s - loss: 0.5124 - accuracy: 0.9310 - val_loss: 0.9871 - val_accuracy: 0.6154 - 53ms/epoch - 53ms/step\n","Epoch 57/100\n","1/1 - 0s - loss: 0.4980 - accuracy: 0.9310 - val_loss: 0.9761 - val_accuracy: 0.6154 - 35ms/epoch - 35ms/step\n","Epoch 58/100\n","1/1 - 0s - loss: 0.4835 - accuracy: 0.9310 - val_loss: 0.9671 - val_accuracy: 0.6154 - 44ms/epoch - 44ms/step\n","Epoch 59/100\n","1/1 - 0s - loss: 0.4688 - accuracy: 0.9310 - val_loss: 0.9623 - val_accuracy: 0.6154 - 52ms/epoch - 52ms/step\n","Epoch 60/100\n","1/1 - 0s - loss: 0.4541 - accuracy: 0.9310 - val_loss: 0.9571 - val_accuracy: 0.6154 - 34ms/epoch - 34ms/step\n","Epoch 61/100\n","1/1 - 0s - loss: 0.4395 - accuracy: 0.9310 - val_loss: 0.9497 - val_accuracy: 0.6154 - 51ms/epoch - 51ms/step\n","Epoch 62/100\n","1/1 - 0s - loss: 0.4250 - accuracy: 0.9310 - val_loss: 0.9397 - val_accuracy: 0.6154 - 56ms/epoch - 56ms/step\n","Epoch 63/100\n","1/1 - 0s - loss: 0.4102 - accuracy: 0.9310 - val_loss: 0.9281 - val_accuracy: 0.6154 - 41ms/epoch - 41ms/step\n","Epoch 64/100\n","1/1 - 0s - loss: 0.3956 - accuracy: 0.9310 - val_loss: 0.9174 - val_accuracy: 0.6154 - 38ms/epoch - 38ms/step\n","Epoch 65/100\n","1/1 - 0s - loss: 0.3811 - accuracy: 0.9310 - val_loss: 0.9070 - val_accuracy: 0.6154 - 53ms/epoch - 53ms/step\n","Epoch 66/100\n","1/1 - 0s - loss: 0.3670 - accuracy: 0.9655 - val_loss: 0.9011 - val_accuracy: 0.6154 - 34ms/epoch - 34ms/step\n","Epoch 67/100\n","1/1 - 0s - loss: 0.3530 - accuracy: 0.9655 - val_loss: 0.8949 - val_accuracy: 0.6154 - 54ms/epoch - 54ms/step\n","Epoch 68/100\n","1/1 - 0s - loss: 0.3392 - accuracy: 0.9655 - val_loss: 0.8883 - val_accuracy: 0.6154 - 56ms/epoch - 56ms/step\n","Epoch 69/100\n","1/1 - 0s - loss: 0.3256 - accuracy: 1.0000 - val_loss: 0.8803 - val_accuracy: 0.6154 - 37ms/epoch - 37ms/step\n","Epoch 70/100\n","1/1 - 0s - loss: 0.3121 - accuracy: 1.0000 - val_loss: 0.8732 - val_accuracy: 0.6154 - 35ms/epoch - 35ms/step\n","Epoch 71/100\n","1/1 - 0s - loss: 0.2989 - accuracy: 1.0000 - val_loss: 0.8681 - val_accuracy: 0.6154 - 35ms/epoch - 35ms/step\n","Epoch 72/100\n","1/1 - 0s - loss: 0.2861 - accuracy: 1.0000 - val_loss: 0.8637 - val_accuracy: 0.6154 - 55ms/epoch - 55ms/step\n","Epoch 73/100\n","1/1 - 0s - loss: 0.2734 - accuracy: 1.0000 - val_loss: 0.8590 - val_accuracy: 0.6154 - 36ms/epoch - 36ms/step\n","Epoch 74/100\n","1/1 - 0s - loss: 0.2611 - accuracy: 1.0000 - val_loss: 0.8540 - val_accuracy: 0.6154 - 33ms/epoch - 33ms/step\n","Epoch 75/100\n","1/1 - 0s - loss: 0.2489 - accuracy: 1.0000 - val_loss: 0.8471 - val_accuracy: 0.6154 - 35ms/epoch - 35ms/step\n","Epoch 76/100\n","1/1 - 0s - loss: 0.2370 - accuracy: 1.0000 - val_loss: 0.8410 - val_accuracy: 0.6154 - 52ms/epoch - 52ms/step\n","Epoch 77/100\n","1/1 - 0s - loss: 0.2255 - accuracy: 1.0000 - val_loss: 0.8366 - val_accuracy: 0.6154 - 55ms/epoch - 55ms/step\n","Epoch 78/100\n","1/1 - 0s - loss: 0.2144 - accuracy: 1.0000 - val_loss: 0.8332 - val_accuracy: 0.6154 - 51ms/epoch - 51ms/step\n","Epoch 79/100\n","1/1 - 0s - loss: 0.2035 - accuracy: 1.0000 - val_loss: 0.8301 - val_accuracy: 0.6154 - 38ms/epoch - 38ms/step\n","Epoch 80/100\n","1/1 - 0s - loss: 0.1929 - accuracy: 1.0000 - val_loss: 0.8279 - val_accuracy: 0.6154 - 41ms/epoch - 41ms/step\n","Epoch 81/100\n","1/1 - 0s - loss: 0.1828 - accuracy: 1.0000 - val_loss: 0.8263 - val_accuracy: 0.6154 - 35ms/epoch - 35ms/step\n","Epoch 82/100\n","1/1 - 0s - loss: 0.1732 - accuracy: 1.0000 - val_loss: 0.8205 - val_accuracy: 0.6154 - 56ms/epoch - 56ms/step\n","Epoch 83/100\n","1/1 - 0s - loss: 0.1639 - accuracy: 1.0000 - val_loss: 0.8177 - val_accuracy: 0.6154 - 33ms/epoch - 33ms/step\n","Epoch 84/100\n","1/1 - 0s - loss: 0.1549 - accuracy: 1.0000 - val_loss: 0.8167 - val_accuracy: 0.6154 - 36ms/epoch - 36ms/step\n","Epoch 85/100\n","1/1 - 0s - loss: 0.1463 - accuracy: 1.0000 - val_loss: 0.8121 - val_accuracy: 0.6154 - 34ms/epoch - 34ms/step\n","Epoch 86/100\n","1/1 - 0s - loss: 0.1380 - accuracy: 1.0000 - val_loss: 0.8078 - val_accuracy: 0.6154 - 36ms/epoch - 36ms/step\n","Epoch 87/100\n","1/1 - 0s - loss: 0.1302 - accuracy: 1.0000 - val_loss: 0.8074 - val_accuracy: 0.6154 - 38ms/epoch - 38ms/step\n","Epoch 88/100\n","1/1 - 0s - loss: 0.1228 - accuracy: 1.0000 - val_loss: 0.8105 - val_accuracy: 0.6154 - 34ms/epoch - 34ms/step\n","Epoch 89/100\n","1/1 - 0s - loss: 0.1158 - accuracy: 1.0000 - val_loss: 0.8103 - val_accuracy: 0.6154 - 35ms/epoch - 35ms/step\n","Epoch 90/100\n","1/1 - 0s - loss: 0.1092 - accuracy: 1.0000 - val_loss: 0.8063 - val_accuracy: 0.6154 - 35ms/epoch - 35ms/step\n","Epoch 91/100\n","1/1 - 0s - loss: 0.1028 - accuracy: 1.0000 - val_loss: 0.8044 - val_accuracy: 0.6154 - 54ms/epoch - 54ms/step\n","Epoch 92/100\n","1/1 - 0s - loss: 0.0969 - accuracy: 1.0000 - val_loss: 0.8049 - val_accuracy: 0.5385 - 38ms/epoch - 38ms/step\n","Epoch 93/100\n","1/1 - 0s - loss: 0.0912 - accuracy: 1.0000 - val_loss: 0.8044 - val_accuracy: 0.5385 - 38ms/epoch - 38ms/step\n","Epoch 94/100\n","1/1 - 0s - loss: 0.0859 - accuracy: 1.0000 - val_loss: 0.8000 - val_accuracy: 0.5385 - 54ms/epoch - 54ms/step\n","Epoch 95/100\n","1/1 - 0s - loss: 0.0810 - accuracy: 1.0000 - val_loss: 0.7960 - val_accuracy: 0.5385 - 34ms/epoch - 34ms/step\n","Epoch 96/100\n","1/1 - 0s - loss: 0.0763 - accuracy: 1.0000 - val_loss: 0.7940 - val_accuracy: 0.5385 - 55ms/epoch - 55ms/step\n","Epoch 97/100\n","1/1 - 0s - loss: 0.0719 - accuracy: 1.0000 - val_loss: 0.7962 - val_accuracy: 0.5385 - 33ms/epoch - 33ms/step\n","Epoch 98/100\n","1/1 - 0s - loss: 0.0678 - accuracy: 1.0000 - val_loss: 0.8008 - val_accuracy: 0.5385 - 38ms/epoch - 38ms/step\n","Epoch 99/100\n","1/1 - 0s - loss: 0.0640 - accuracy: 1.0000 - val_loss: 0.8029 - val_accuracy: 0.5385 - 55ms/epoch - 55ms/step\n","Epoch 100/100\n","1/1 - 0s - loss: 0.0604 - accuracy: 1.0000 - val_loss: 0.8027 - val_accuracy: 0.5385 - 34ms/epoch - 34ms/step\n"]}],"source":["history = model.fit(X, y, epochs = 100, validation_split=0.3, verbose=2)"]},{"cell_type":"code","source":["##############################################################################################################################################################"],"metadata":{"id":"czwGytHmmuhp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Phần này bỏ"],"metadata":{"id":"U8aeWbzBVgbe"}},{"cell_type":"code","source":["# Use a pipeline as a high-level helper\n","from transformers import pipeline, DataCollatorForLanguageModeling, TrainingArguments, Trainer\n","\n","pipe = pipeline(\"fill-mask\", model=\"albert-base-v2\")\n","\n","# Load model directly\n","from transformers import AutoTokenizer, AutoModelForMaskedLM\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"albert-base-v2\")\n","model = AutoModelForMaskedLM.from_pretrained(\"albert-base-v2\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":269,"referenced_widgets":["08beaa04eae8424997a70fba2a7e9aca","d0b5837fd7174ae28c42587727745ffa","b0230271b5de4784a6a7e60563ef75ba","c30fd7685a2e44a1ab4915edfd80ddf0","1945ec431b3e4971baf7e9ebd74be0c3","b26df5cea4d14c45990c8f48655999bb","36776434adf54ee7946cbd3927efb132","bbdeb53cd47d4878a09cc92debcb9076","12a2cc13a33b407ca00f096f97629fdc","071c21ba72a44a6ba59eaeaf4fa89fa5","7b125381f5ed43bc9644a2e0c94ae40b","edfb3291688a4a2789dd2bad3078679d","a3762d70da9a45baad637564d2dc4d65","dad1c472af014d2caec56241ceff0eab","a61e9606f768406ab320e928176660e7","b75c56e7bb3c4f1e8be61a1f42c9132d","dabf16b06c23431e9bb304d81c886883","9e66319a7b4c4e40ace3c0137cc90037","65fcfedb9c9b471eae8cf1bdda0a8f5d","b9bfcfa05783415387b63daeaf2b9ad8","0d562457b1414415903e5316aa286e69","329f3297686e460c87608ae2424bc929","4b12f197005c48f7a2bb040a795cb448","79499e78b7244a35842c15b854befa64","96999b463af04d54883561bc88274a53","1e0903cbca7a434a8b2b1f3fef0c125f","f1dea1221d934153be027f78af7576da","656b7a5ae1e146f5a9a75056f562c40c","513d62ca85fd43a3a69c8ef077885d7d","9d6b5e5019474461b11a178b0316eca2","b869b1a995874c0d9b4aa0a109f7a3e4","143f12018a36435aa867ffc479f0ba9b","9ed80dd6bd504ab08110b8097e79aca9","582f75de808a4b81b5b73aac358c0a18","d17e56ed33044704bd6f0b554af70e23","15a59c011d25440f958fb0c826f8b770","fa71d471890e43af9a545a7f7b07d536","db03176b82e2483093379499a53aff92","ffd1e3eda3e04285832da0894488a9dc","7925e5525e5d4fdf84005695949b3126","f7a941527cdf4a97a1a94acc445fdac7","8feb247926ba4631b81386a8398d8fae","09f1f386cfa040d3af5c74dd7f00ae53","2dea2d24dac342fa944baf0de831bd9d"]},"id":"qRgpmc2MiZ1u","executionInfo":{"status":"ok","timestamp":1695216382938,"user_tz":-420,"elapsed":6074,"user":{"displayName":"9370 _ Phạm Thiện Tài","userId":"17496006235026682420"}},"outputId":"dffd1330-59cd-471b-8c31-4905502859b5"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/684 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08beaa04eae8424997a70fba2a7e9aca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading model.safetensors:   0%|          | 0.00/47.4M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"edfb3291688a4a2789dd2bad3078679d"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at albert-base-v2 were not used when initializing AlbertForMaskedLM: ['albert.pooler.bias', 'albert.pooler.weight']\n","- This IS expected if you are initializing AlbertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing AlbertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading (…)ve/main/spiece.model:   0%|          | 0.00/760k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b12f197005c48f7a2bb040a795cb448"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.31M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"582f75de808a4b81b5b73aac358c0a18"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at albert-base-v2 were not used when initializing AlbertForMaskedLM: ['albert.pooler.bias', 'albert.pooler.weight']\n","- This IS expected if you are initializing AlbertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing AlbertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}]},{"cell_type":"code","source":["model.resize_token_embeddings(len(tokenizer))\n","tokenizer.pad_token = tokenizer.eos_token"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M-uZDYQhkOtj","executionInfo":{"status":"ok","timestamp":1695216384725,"user_tz":-420,"elapsed":7,"user":{"displayName":"9370 _ Phạm Thiện Tài","userId":"17496006235026682420"}},"outputId":"afbd6740-1b64-48e8-ef9b-ecd965bdda7e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 30000. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n"]}]},{"cell_type":"code","source":["# Data collator for padding\n","data_collator = DataCollatorForLanguageModeling(tokenizer,mlm=False,return_tensors=\"pt\")"],"metadata":{"id":"y87eydRwoFpF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load dataset\n","train_dataset = df['sentence'].values\n","test_dataset = df['sentiment'].values"],"metadata":{"id":"w2mhg_drpFXy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import math\n","\n","batch_size=6\n","gradient_accumulation_steps=2\n","\n","step_per_batch = math.ceil(len(train_dataset) / (batch_size * gradient_accumulation_steps))\n","print('step_per_batch',step_per_batch)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"urxs9Blvoos8","executionInfo":{"status":"ok","timestamp":1695216446061,"user_tz":-420,"elapsed":506,"user":{"displayName":"9370 _ Phạm Thiện Tài","userId":"17496006235026682420"}},"outputId":"f136c1c6-c53a-4ae8-9e74-e1573e1d3975"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["step_per_batch 4\n"]}]},{"cell_type":"code","source":["#pip install torch torchvision torchaudio"],"metadata":{"id":"ZMH_s21wxyYP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train(model):\n","    training_args = TrainingArguments(\n","        output_dir='training_article',\n","        per_device_train_batch_size=batch_size,\n","        gradient_accumulation_steps=gradient_accumulation_steps,\n","        evaluation_strategy='steps',\n","        num_train_epochs=30,\n","        save_steps=step_per_batch,\n","        eval_steps=step_per_batch,\n","        logging_steps=step_per_batch,\n","        learning_rate=0.001,\n","        warmup_steps=step_per_batch * 5,\n","        save_total_limit=5,\n","        load_best_model_at_end=True,\n","        prediction_loss_only=True,\n","        metric_for_best_model='loss',\n","    )\n","    trainer = Trainer(\n","        model=model,\n","        data_collator=data_collator,\n","        args=training_args,\n","        train_dataset=train_dataset,\n","        eval_dataset=test_dataset,\n","        tokenizer=tokenizer,\n","        callbacks=[EarlyStoppingCallback(early_stopping_patience=4)]\n","    )\n","\n","    trainer.place_model_on_device=False\n","    trainer.train()\n","    trainer.save_model('training_article/best_model')\n","    tokenizer.save_pretrained(\"training_article/best_model\")\n","\n","train(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":494},"id":"mlu0ECRbqRZt","executionInfo":{"status":"error","timestamp":1695216563552,"user_tz":-420,"elapsed":16,"user":{"displayName":"9370 _ Phạm Thiện Tài","userId":"17496006235026682420"}},"outputId":"3cf96f0f-e30f-4ec2-f895-1a56603a3703"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ImportError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-2a0cc7e9a0a4>\u001b[0m in \u001b[0;36m<cell line: 33>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training_article/best_model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-20-2a0cc7e9a0a4>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     training_args = TrainingArguments(\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0moutput_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'training_article'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mper_device_train_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mgradient_accumulation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgradient_accumulation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/training_args.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, output_dir, overwrite_output_dir, do_train, do_eval, do_predict, evaluation_strategy, prediction_loss_only, per_device_train_batch_size, per_device_eval_batch_size, per_gpu_train_batch_size, per_gpu_eval_batch_size, gradient_accumulation_steps, eval_accumulation_steps, eval_delay, learning_rate, weight_decay, adam_beta1, adam_beta2, adam_epsilon, max_grad_norm, num_train_epochs, max_steps, lr_scheduler_type, warmup_ratio, warmup_steps, log_level, log_level_replica, log_on_each_node, logging_dir, logging_strategy, logging_first_step, logging_steps, logging_nan_inf_filter, save_strategy, save_steps, save_total_limit, save_safetensors, save_on_each_node, no_cuda, use_cpu, use_mps_device, seed, data_seed, jit_mode_eval, use_ipex, bf16, fp16, fp16_opt_level, half_precision_backend, bf16_full_eval, fp16_full_eval, tf32, local_rank, ddp_backend, tpu_num_cores, tpu_metrics_debug, debug, dataloader_drop_last, eval_steps, dataloader_num_workers, past_index, run_name, disable_tqdm, remove_unused_columns, label_names, load_best_model_at_end, metric_for_best_model, greater_is_better, ignore_data_skip, sharded_ddp, fsdp, fsdp_min_num_params, fsdp_config, fsdp_transformer_layer_cls_to_wrap, deepspeed, label_smoothing_factor, optim, optim_args, adafactor, group_by_length, length_column_name, report_to, ddp_find_unused_parameters, ddp_bucket_cap_mb, ddp_broadcast_buffers, datalo...\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/training_args.py\u001b[0m in \u001b[0;36m__post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1403\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mis_torch_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1405\u001b[0;31m             \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1406\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"npu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1407\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mget_xla_device_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"GPU\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/training_args.py\u001b[0m in \u001b[0;36mdevice\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1850\u001b[0m         \"\"\"\n\u001b[1;32m   1851\u001b[0m         \u001b[0mrequires_backends\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"torch\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1852\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_devices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1854\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36m__get__\u001b[0;34m(self, obj, objtype)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mcached\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcached\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0mcached\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m             \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/training_args.py\u001b[0m in \u001b[0;36m_setup_devices\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1765\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_sagemaker_mp_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1766\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_accelerate_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_version\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0.20.1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1767\u001b[0;31m                 raise ImportError(\n\u001b[0m\u001b[1;32m   1768\u001b[0m                     \u001b[0;34m\"Using the `Trainer` with `PyTorch` requires `accelerate>=0.20.1`: Please run `pip install transformers[torch]` or `pip install accelerate -U`\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1769\u001b[0m                 )\n","\u001b[0;31mImportError\u001b[0m: Using the `Trainer` with `PyTorch` requires `accelerate>=0.20.1`: Please run `pip install transformers[torch]` or `pip install accelerate -U`","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","source":[],"metadata":{"id":"1R2iPCuNwkZZ"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1ekPneZbgxOrsJtmHfMisawWfsfgVWGoD","authorship_tag":"ABX9TyOPNfFd52xWmKF2tGLhgP5C"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"3edbc834d4bc48ffab0394ddb712ff7c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2426f6af287b4738930f1c191cc29137","IPY_MODEL_d565ede754cf4cf5a076d542863ce995","IPY_MODEL_687b220d15854ed39cfc8430122d47a6"],"layout":"IPY_MODEL_a53deacb41324cfbad017a249ace602d"}},"2426f6af287b4738930f1c191cc29137":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cd18866eb83642fda9777ce42dd05143","placeholder":"​","style":"IPY_MODEL_c088c0a2651e42ee9c9823004910619d","value":"Downloading (…)lve/main/config.json: 100%"}},"d565ede754cf4cf5a076d542863ce995":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5c5db40a71a24f92a9a9309555c19a1a","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f11061e4314b417284fb327c3f3d0cb2","value":570}},"687b220d15854ed39cfc8430122d47a6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_14ab10f1dc904573847ce43fb40f5cdb","placeholder":"​","style":"IPY_MODEL_ec2e261203b549048f7199bd6396a401","value":" 570/570 [00:00&lt;00:00, 10.7kB/s]"}},"a53deacb41324cfbad017a249ace602d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd18866eb83642fda9777ce42dd05143":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c088c0a2651e42ee9c9823004910619d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5c5db40a71a24f92a9a9309555c19a1a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f11061e4314b417284fb327c3f3d0cb2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"14ab10f1dc904573847ce43fb40f5cdb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec2e261203b549048f7199bd6396a401":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"60224e5ce378433b8007f7e979e71f81":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_052ca36bd8a14c4a916c01fe3bb71760","IPY_MODEL_e8f85f531de0488bacc428e0ea9900ea","IPY_MODEL_7e742605a70945e19d245068dd5c8607"],"layout":"IPY_MODEL_dcccf55628f148448aa455778e1da65f"}},"052ca36bd8a14c4a916c01fe3bb71760":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5941aa4415364146a527d92a60d08ac4","placeholder":"​","style":"IPY_MODEL_f4cc2f5383b94491a67c0d83738756eb","value":"Downloading model.safetensors: 100%"}},"e8f85f531de0488bacc428e0ea9900ea":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9f329ab401dd48cf9f6a03fed5ec015d","max":440449768,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0ac25e2183b94e5b923c0a9e5f9333f3","value":440449768}},"7e742605a70945e19d245068dd5c8607":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ab415fcfdfb640b6886924c6317f9abd","placeholder":"​","style":"IPY_MODEL_cfa74d591d314ae0ad57783544a6bf98","value":" 440M/440M [00:05&lt;00:00, 146MB/s]"}},"dcccf55628f148448aa455778e1da65f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5941aa4415364146a527d92a60d08ac4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f4cc2f5383b94491a67c0d83738756eb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9f329ab401dd48cf9f6a03fed5ec015d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0ac25e2183b94e5b923c0a9e5f9333f3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ab415fcfdfb640b6886924c6317f9abd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cfa74d591d314ae0ad57783544a6bf98":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"08beaa04eae8424997a70fba2a7e9aca":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d0b5837fd7174ae28c42587727745ffa","IPY_MODEL_b0230271b5de4784a6a7e60563ef75ba","IPY_MODEL_c30fd7685a2e44a1ab4915edfd80ddf0"],"layout":"IPY_MODEL_1945ec431b3e4971baf7e9ebd74be0c3"}},"d0b5837fd7174ae28c42587727745ffa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b26df5cea4d14c45990c8f48655999bb","placeholder":"​","style":"IPY_MODEL_36776434adf54ee7946cbd3927efb132","value":"Downloading (…)lve/main/config.json: 100%"}},"b0230271b5de4784a6a7e60563ef75ba":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bbdeb53cd47d4878a09cc92debcb9076","max":684,"min":0,"orientation":"horizontal","style":"IPY_MODEL_12a2cc13a33b407ca00f096f97629fdc","value":684}},"c30fd7685a2e44a1ab4915edfd80ddf0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_071c21ba72a44a6ba59eaeaf4fa89fa5","placeholder":"​","style":"IPY_MODEL_7b125381f5ed43bc9644a2e0c94ae40b","value":" 684/684 [00:00&lt;00:00, 32.9kB/s]"}},"1945ec431b3e4971baf7e9ebd74be0c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b26df5cea4d14c45990c8f48655999bb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"36776434adf54ee7946cbd3927efb132":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bbdeb53cd47d4878a09cc92debcb9076":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"12a2cc13a33b407ca00f096f97629fdc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"071c21ba72a44a6ba59eaeaf4fa89fa5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b125381f5ed43bc9644a2e0c94ae40b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"edfb3291688a4a2789dd2bad3078679d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a3762d70da9a45baad637564d2dc4d65","IPY_MODEL_dad1c472af014d2caec56241ceff0eab","IPY_MODEL_a61e9606f768406ab320e928176660e7"],"layout":"IPY_MODEL_b75c56e7bb3c4f1e8be61a1f42c9132d"}},"a3762d70da9a45baad637564d2dc4d65":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dabf16b06c23431e9bb304d81c886883","placeholder":"​","style":"IPY_MODEL_9e66319a7b4c4e40ace3c0137cc90037","value":"Downloading model.safetensors: 100%"}},"dad1c472af014d2caec56241ceff0eab":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_65fcfedb9c9b471eae8cf1bdda0a8f5d","max":47372894,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b9bfcfa05783415387b63daeaf2b9ad8","value":47372894}},"a61e9606f768406ab320e928176660e7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0d562457b1414415903e5316aa286e69","placeholder":"​","style":"IPY_MODEL_329f3297686e460c87608ae2424bc929","value":" 47.4M/47.4M [00:00&lt;00:00, 162MB/s]"}},"b75c56e7bb3c4f1e8be61a1f42c9132d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dabf16b06c23431e9bb304d81c886883":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e66319a7b4c4e40ace3c0137cc90037":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"65fcfedb9c9b471eae8cf1bdda0a8f5d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b9bfcfa05783415387b63daeaf2b9ad8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0d562457b1414415903e5316aa286e69":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"329f3297686e460c87608ae2424bc929":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4b12f197005c48f7a2bb040a795cb448":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_79499e78b7244a35842c15b854befa64","IPY_MODEL_96999b463af04d54883561bc88274a53","IPY_MODEL_1e0903cbca7a434a8b2b1f3fef0c125f"],"layout":"IPY_MODEL_f1dea1221d934153be027f78af7576da"}},"79499e78b7244a35842c15b854befa64":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_656b7a5ae1e146f5a9a75056f562c40c","placeholder":"​","style":"IPY_MODEL_513d62ca85fd43a3a69c8ef077885d7d","value":"Downloading (…)ve/main/spiece.model: 100%"}},"96999b463af04d54883561bc88274a53":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9d6b5e5019474461b11a178b0316eca2","max":760289,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b869b1a995874c0d9b4aa0a109f7a3e4","value":760289}},"1e0903cbca7a434a8b2b1f3fef0c125f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_143f12018a36435aa867ffc479f0ba9b","placeholder":"​","style":"IPY_MODEL_9ed80dd6bd504ab08110b8097e79aca9","value":" 760k/760k [00:00&lt;00:00, 27.6MB/s]"}},"f1dea1221d934153be027f78af7576da":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"656b7a5ae1e146f5a9a75056f562c40c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"513d62ca85fd43a3a69c8ef077885d7d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9d6b5e5019474461b11a178b0316eca2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b869b1a995874c0d9b4aa0a109f7a3e4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"143f12018a36435aa867ffc479f0ba9b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ed80dd6bd504ab08110b8097e79aca9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"582f75de808a4b81b5b73aac358c0a18":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d17e56ed33044704bd6f0b554af70e23","IPY_MODEL_15a59c011d25440f958fb0c826f8b770","IPY_MODEL_fa71d471890e43af9a545a7f7b07d536"],"layout":"IPY_MODEL_db03176b82e2483093379499a53aff92"}},"d17e56ed33044704bd6f0b554af70e23":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ffd1e3eda3e04285832da0894488a9dc","placeholder":"​","style":"IPY_MODEL_7925e5525e5d4fdf84005695949b3126","value":"Downloading (…)/main/tokenizer.json: 100%"}},"15a59c011d25440f958fb0c826f8b770":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f7a941527cdf4a97a1a94acc445fdac7","max":1312669,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8feb247926ba4631b81386a8398d8fae","value":1312669}},"fa71d471890e43af9a545a7f7b07d536":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_09f1f386cfa040d3af5c74dd7f00ae53","placeholder":"​","style":"IPY_MODEL_2dea2d24dac342fa944baf0de831bd9d","value":" 1.31M/1.31M [00:00&lt;00:00, 2.73MB/s]"}},"db03176b82e2483093379499a53aff92":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ffd1e3eda3e04285832da0894488a9dc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7925e5525e5d4fdf84005695949b3126":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f7a941527cdf4a97a1a94acc445fdac7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8feb247926ba4631b81386a8398d8fae":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"09f1f386cfa040d3af5c74dd7f00ae53":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2dea2d24dac342fa944baf0de831bd9d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}